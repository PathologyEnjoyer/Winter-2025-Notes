
\documentclass[x11names,reqno,14pt]{extarticle}
\input{preamble}
\usepackage[document]{ragged2e}
\usepackage{epsfig}
\usepackage{dynkin-diagrams}
\usepackage{pgfkeys}
\usepackage{pgfopts}
\usepackage{xcolor}
\usepackage{ytableau}

\pagestyle{fancy}{
	\fancyhead[L]{Winter 2025}
	\fancyhead[C]{MAT445F}
	\fancyhead[R]{John White}
  
  \fancyfoot[R]{\footnotesize Page \thepage \ of \pageref{LastPage}}
	\fancyfoot[C]{}
	}
\fancypagestyle{firststyle}{
     \fancyhead[L]{}
     \fancyhead[R]{}
     \fancyhead[C]{}
     \renewcommand{\headrulewidth}{0pt}
	\fancyfoot[R]{\footnotesize Page \thepage \ of \pageref{LastPage}}
}
\newcommand{\pmat}[4]{\begin{pmatrix} #1 & #2 \\ #3 & #4 \end{pmatrix}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\B}{\mathbb{B}}
\newcommand{\fin}{``\in"}
\newcommand{\mk}[1]{\mathfrak{#1}}
\newcommand{\g}{\mk{g}}
\newcommand{\h}{\mk{h}}
\newcommand{\J}{\mc{J}}
\newcommand{\tphi}{\tilde{\phi}}
\newcommand{\pois}[2]{\{#1,#2\}}
\newcommand{\fibrate}[3]{\begin{tikzcd} #1 \ar[d, "#2"] \\ #3 \end{tikzcd}}
\newcommand{\bark}{\bar{k}}
\newcommand{\so}{\mk{s}\mk{o}}
\newcommand{\rad}{rad}
\renewcommand{\sp}{\mk{s}\mk{p}}
\renewcommand{\t}{\mk{t}}
\DeclareMathOperator{\Perm}{Perm}
\DeclareMathOperator{\pdim}{pdim}
\DeclareMathOperator{\gldim}{gldim}
\DeclareMathOperator{\lgldim}{lgldim}
\DeclareMathOperator{\rgldim}{rgldim}
\DeclareMathOperator{\idim}{idim}
\DeclareMathOperator{\SU}{SU}
\DeclareMathOperator{\SO}{SO}
\DeclareMathOperator{\Ad}{Ad}
\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\gr}{gr}
\DeclareMathOperator{\Sig}{Sig}
\DeclareMathOperator{\Res}{Res}
\DeclareMathOperator{\Der}{Der}
\newcommand{\Rmod}{R-\text{mod}}
\newcommand{\RMod}{R-\text{Mod}}
\newcommand{\onto}{\twoheadrightarrow}
\newcommand{\into}{\hookrightarrow}
\newcommand{\barf}{\bar{f}}
\newcommand{\dd}[2]{\frac{d#1}{d#2}}
\newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\gl}{\mk{g}\mk{l}}
\renewcommand{\sl}{\mk{s}\mk{l}}
\newcommand{\spew}{\Sp(E,\omega)}
\newcommand{\jew}{\mc{J}(E,\omega)}
\renewcommand{\P}{\mathbb{P}}
\renewcommand{\E}{\mathbb{E}}
\DeclareMathOperator{\Ext}{Ext}
\DeclareMathOperator{\Rank}{Rank}
\DeclareMathOperator{\Sp}{Sp}
\DeclareMathOperator{\ann}{ann}
\DeclareMathOperator{\Lag}{Lag}
\DeclareMathOperator{\Riem}{Riem}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\Ind}{Ind}
\DeclareMathOperator{\PSL}{PSL}
\newcommand{\exactlon}[5]{
		\begin{tikzcd}
			0\ar[r]&#1\ar[r,"#2"]& #3 \ar[r,"#4"]& #5 \ar[r]&0
		\end{tikzcd}
}



\title{MAT445}
\author{John White}
\date{Winter 2025}


\begin{document}

\section*{Lecture 1 - 7/1/25}

Missed :(

\section*{Lecture 2 - 9/1/25}

Missed :(

\section*{Lecture 3 - 14/1/25}

\subsection*{\underline{Character theory}}

Consider $\dim\Hom_G(\rho_i,\rho_j) = 1$ if $i = j$ and $0$ if $i \neq j$ (meaning if $\rho_i\not\cong\rho_j$)

Recall: Given a representation $\rho:G\to \GL_n(k)$, the character of $\rho$, $\chi_\rho$, is given by $\chi_\rho:G\to k, g \mapsto \tr(\rho(g))$

For today, $G$ will be finite, $k = \bar{k}$ will be algebraically closed, of characteristic 0. 

Basic properties of characters: 
\begin{enumerate}

\item Suppose $\rho:G\to\GL_n(k)$ is a representation: then $\chi_\rho(e) = n = \dim \rho$. 

\item $\chi_\rho(g) = \chi_\rho(hgh^{-1})$ for all $g, h \in G$, i.e. $\chi_\rho$ is constant on each conjugacy class of $G$. 

\defn

A function $f:G\to k$ which is constant on conjugacy classes is called a \underline{class function}. 

The $\rho_i$ (isomorphism classes of reps) will form an ONB for the space of class functions.  

Given $\rho_1:G\to \GL_n(k), \rho_2:G\to \GL_m(k)$, $\chi_{\rho_1\oplus\rho_2} = \chi_{\rho_1} + \chi_{\rho_2}$

\item $\chi_{\rho_1\otimes\rho_2} = \chi_{\rho_1}\chi_{\rho_2}$

To see this, let $A, B$ be diagonalizable (which we have WLOG because the image of any finite group are all diagonalizable over an algebraically closed $k$ of char 0, which follows from Jordan Normal form)

Then $\tr(A\otimes B)=\tr(A)\tr(B)$. 

I can't see the board he's writing on very well, and also I am not sure how $A\otimes B$ was defined. 

\end{enumerate}


\claim

$\chi_\rho:G\to k$ always factors through $\Q(\mu_\oo)$, the subfield of $k$ containing $\Q$ ($k$ has char 0) generated by all roots of unity ($k = \bar{k}$)

\proof

Because $G$ is finite, $\rho_G$ has finite order, hence its eigenvalues are roots of unity, so the trace is the sum of roots of unity. 

\qed

\defn

$\bar{\cdot}:\Q(\mu_\oo) \to \Q(\mu_\oo)$  is the unique field homomorphism with the property that $\bar{\zeta} = \zeta^{-1}$ for all roots of unity $\zeta \in \Q(\mu_\oo)$. 

\begin{enumerate}

\item[5] $\chi_{\rho^v}= \bar{\chi_\rho}$

Recall $\rho^v$ is defined via the formula $g\cdot f = f(g^{-1}\cdot -)$ where $f$ is a functional. We have 
\begin{align*}
\chi_{\rho^v}(g) & = \tr(p(g^{-1})) \\
& = \sum_{\zeta\text{ is an eigenvalue of }\rho(G)}\zeta^{-1} \\
& = \sum \bar{\zeta} = \bar{\chi_\rho(g)}
\end{align*}

This also follows from the Hom-tensor adjunction because $\Hom_k(\rho_1,\rho_2) = \rho_1^v\otimes\rho_2$. 

\end{enumerate}

\defn

Let $\chi,\psi:G\to \Q(\mu_\oo)$ be class functions. We define their inner product by 
\[
\langle\chi,\psi\rangle = \frac{1}{|G|}\sum_{g\in G}\chi(g)\bar{\psi(g)}
\] 
This indeed is a positive definite non degenerate. 

Let $\rho_1:G\to\GL_n(k), \rho_2:G\to\GL_m(k)$. What is $\langle\chi_{\rho_1},\chi_{\rho_2}\rangle$? 
\thm
\[
\langle\chi_{\rho_1},\chi_{\rho_2}\rangle = \dim_k\Hom_G(\rho_1,\rho_2) = \dim_k\Hom(\rho_1,\rho_2)^G
\]

\cor

Suppose $\rho_1,\rho_2$ are irreducible. Then $\langle\chi_{\rho_1},\chi_{\rho_2}\rangle$ is 0 if $\rho_1,\rho_2$ are not isomorphic, and $1$ if they are. So the $\rho_i$ form an orthonormal basis for the space of class functions. 

\qed

\proof

Let $R_G \in k[G]$ be the element given by 
\[
R_G = \frac{1}{|G|}\sum_{g\in G}eg
\]

We want to show 
\begin{enumerate}

\item for $v \in V^G, R_G\cdot v = v$. 

\item For arbitrary $v \in V, R_G\cdot v \in V^G$

\end{enumerate}

To check:

\begin{enumerate}

\item We have 
\begin{align*}
R_G\cdot v & = \frac{1}{|G|}\sum_{g\in G}e_g\cdot v \\
& = \frac{1}{|G|}\sum_{g\in G}v \\
& = v\\
\end{align*}

\item Fix $g \in G$. Then 
\begin{align*}
g\cdot R_G\cdot v & = g\cdot (\frac{1}{|G|}\sum_{h\in G}hv) \\
& = \frac{1}{|G|} \sum_{h\in G}gh\cdot v \\
& = \frac{1}{|G|}\sum_{h\in G}h\cdot v \\
& = R_G\cdot v
\end{align*}
\end{enumerate}

\cor

Let $V$ be a $G$-representation. Then $\dim_kV^G = \tr(R_G|V)$

\proof

\claim

$\tr($projection$) = \dim_k\Im$

\proof

Claim$\implies$Cor follows from $\tr(R_G) = \dim\Im(R_G|V) = \dim_kV^G$

\qed

We can finally prove the theorem: 

\proof

\begin{align*}
\dim_k\Hom_G(\rho_1,\rho_2) & = \dim_k\Hom_k(\rho_1,\rho_2)^G \\
& = \tr(R_G|\Hom_k(\rho_1,\rho_2)) \\
& = \tr(\frac{1}{|G|}\sum e_g|\Hom_k(\rho_1,\rho_2)) \\
& = \frac{1}{|G|}\tr(g|\hom_k(\rho_1,\rho_2)) \\
& = \frac{1}{|G|}\sum_{g\in G}\chi_{\hom_k(\rho_1,\rho_2)}(g) \\
& = \frac{1}{|G|}\sum_{g\in G}\bar{\chi_{\rho_1}}\chi_{\rho_2} \\
& = \langle\chi_{\rho_1},\chi_{\rho_2} \rangle \\
& = \bar{\underbrace{\langle\chi_{\rho_2},\chi_{\rho_1}\rangle}_{\in \Z}} \\
\end{align*}

\qed

\section*{Lecture 4, 16/1/24}

As always, $G$ will be a finite group, $k = \bar{k}$ is an algebraically closed field of characteristic 0. 

$\Q(\mu_\oo)$ is the algebraically closed subfield of $\C$ which contains all the roots of unity, and this comes with the complex conjugate $\bar{\cdot}, \zeta\mapsto\zeta^{-1}$. 

Goal: Classify finite dimensional $G$-representations over $k$. 

We have done:
\begin{enumerate}

\item Maschke's theorem, which states that any $G$-rep in $V$ over $k$ is semisimple. 

\item Character theory: $V \sim \chi_V:G\to\Q(\mu_\oo)\subseteq k$ , $g \mapsto \tr(g|V)$

\end{enumerate}

\defn

$Cl(G)$ denotes the class functions $G \mapsto \Q(\mu_\oo)$, and it is equipped with an inner product, 
\[
\langle\psi,\varphi\rangle = \frac{1}{|G|}\sum_{g\in G}\psi(g)\bar{\varphi(g)}
\]

Remark: There is an isomorphism $Cl(G) \simeq Z(\Q(\mu_\oo)[G])$, sending $\varphi$ to $\sum_{g\in G}\phi(g)e_g$

Warning: They come with different ring structures which are not preserved by this isomorphism. 

Last time we used the Reynolds operator to show $\langle\chi_V,\chi_W\rangle = \dim_k\Hom_G(V, W)$. 

If $\rho_1,\rho_2$ are irreps of $G$, then $\langle\chi_{\rho_1},\chi_{\rho_2}\rangle$ is $1$ if $\rho_1\cong\rho_2$, and 0 otherwise. 

\cor

$\#$ of conjugacy classes of irreducible representations of $G \leq \dim_{\Q(\mu_\oo)}Cl(G) = \#$ of conjugacy classes of $G$

\proof

If $\chi_{\rho_i}$ are orthonormal, then the number of conjugacy classes of irreps is equal to $\dim \Span(\chi_{\rho_i}) \subseteq Cl(G)$, so this number is $\leq \dim Cl(G)$

\qed

\prop

Let $V$ be a $G$-representation. Then 
\[
\Phi_V:\oplus_{\rho_i\text{ irrep of }G}\rho_i\otimes_k\Hom_G(\rho_i, V) \to V
\]
given by $v\otimes f \mapsto f(v)$ is an isomorphism. 

\proof

First, we show it is surjective. By Maschke, $V = \oplus_{\rho_i \text{ reps }G}\rho_i^{n_i}$. 

Let $v \in \rho_i^{n_i}\subseteq V$, $v = (v_1, \dots, v_{n_i})$. Let $f_j:\rho_j\to \rho_i^{n_i}$ be the inclusion of the $j$th coordinate.

Then $\Phi_v(\sum_jv_j\otimes f_j) = v$. 

Now we show injectivity. 

We have
\[
\dim_k\oplus\rho_i\otimes_k\Hom_G(\rho_i,V) = \dim_kV
\]
This follows from 
\[
\dim_k\Hom_G(\rho_i,V) = n_i
\]
This follows from 
\begin{align*}
\Hom_G(\rho_i,V) & = \Hom_G(\rho_i,\oplus\rho_i^{n_i}) \\
& = \oplus_j\Hom_G(\rho_i,\rho_j)^{n_i} \\
& = \Hom_G(\rho_i,\rho_j)^{n_i} \\
\end{align*}
Which is $n_i$-dimensional
\[
\dim_k\oplus\rho_i\otimes\Hom_G(\rho_i,V) = \sum n_i\dim_k\rho_i = \dim V
\]

\qed

\cor

\[
V \simeq \oplus_{\rho\text{ irreps of }G}\rho_i^{\langle\chi_{\rho_i},\chi_{V}\rangle}
\]

\proof

Enough to show $\rho_i^{\langle\rho_i,V\rangle } \simeq \rho_i\otimes_k\Hom_G(\rho_i,V)$, i.e. $\dim_k\Hom(\rho_i,V) = \langle\chi_{\rho_i},\chi_{\rho_j}\rangle$. But that's the theorem. 

\qed

\cor

\[
V \simeq \oplus_{\rho_i\text{irreps}}\rho_i^{\oplus n_i}
\]
, then $\langle \chi_V,\chi_V\rangle = \sum_in_i^2$

\proof

$\chi_V = \sum n_i\chi_{\rho_i}$

\qed

\cor

$V \simeq W\iff \chi_V = \chi_W$

\cor

$V$ is irreducible if and only if $\langle\chi_V,\chi_V\rangle = 1$. 

\proof

Write $V = \oplus_i\rho_i^{n_i}$: so $\langle\chi_V,\chi_V\rangle = \sum_in_i^2$ is equal to 1 iff exactly $1$ $n_i$ is nonzero, and equal to 1. 

\qed

\exm(The regular representation)

Let $G \curvearrowright k(G)$ via left multiplication. 

$\chi_{k[G]}(g) = \tr(g|k[G])$, which is $|G|$ if $g$ is the identity, and 0 otherwise. 

Because $g\cdot e_{g'} = e_{gg'}$, we have
\[
\tr(g|k[G]) = \#\{h\in G \mid gh = g\}
\]

Remark: if $X$ is a $G$-set (i.e. a set with a $G$-action), then the permutation representation, $k^X,$ has character 

\[
\chi_{k^X}(g) = \#\{x\in X \mid g\cdot x = x\}
\]

\cor

As a $G$-representation, 
\[
k[G] \simeq \oplus_{\rho_i\text{ irrep }}\rho_i^{\oplus\dim\rho_i}
\]

\proof

\begin{align*}
\langle\chi_{\rho_i},\chi_{k[G]}\rangle & = \frac{1}{|G|}\sum_{g\in G}\chi_{\rho_i}(g)\bar{\chi_{k[G]}(g)} \\
& = \frac{1}{|G|}\chi_{\rho_i}(e)\bar{\chi_{k[G]}(e)} \\
& = \frac{1}{|G|}\dim\rho_i |G| \\
& = \dim\rho_i
\end{align*}
Because this representation is 0 except at the identity. 

\qed

Remark: In fact, $\Hom_G(k[G],\rho_i)\simeq\rho_i$, AS A VECTOR SPACE.

\proof

$\Hom_G(k[G],\rho_i) = \Hom_{k[G]}(k[G],\rho_i) \simeq \rho_i$ AS A VECTOR SPACE

\qed

\cor

Let $\rho_i$ be the (conjugacy classes of) irreps of $G$, $n_i$ the dimension of $\rho_i$. 

Then $\sum_in_i^2= |G|$. 

\proof

$|G| = \dim_kk[G] = \dim_k\oplus_i\rho_i^{\oplus\dim\rho_i} = \sum n_i^2$

\qed

\thm

Let $G$ be a finite group, $k = \bar{k}$ an algebraically closed field of characteristic 0, $\rho_1,\dots,\rho_n$ the irreps of $G$. Then $\{\chi_{\rho_i}\}$ is an orthonormal basis of $Cl(G)$.

\proof

We know it's orthonormal (so in particular linearly independent), so it is left to show that this indeed spans all of $Cl(G)$. 

What remains to show is that $\chi_{\rho_i}$ span $Cl(G)$.

It is enough to show that if $\psi\in Cl(G)$ with $\langle\psi,\chi_{\rho_i}\rangle = 0$ for all $i$, then $\psi = 0$, i.e. the orthogonal complement of the span of the $\chi_{\rho_i}$ is trivial. 

\defn

If $\psi:G\to\Q(\mu_\oo)$ is a class function, 
\[
\gamma_\psi\eqdef\sum_{g\in G}\psi(g)e_g \in Z(k[G])
\]

\exm

If $\psi:G\to k$, $g \mapsto \frac{1}{|G|}$, $\gamma_\psi = R_G$. 

We will compute what $\gamma_\psi$ does to a representation. 

\prop 

If $\rho$ is an irreducible representation of $G$, then $\gamma_\psi:\rho\to\rho$ is multiplication by the scalar $\frac{|G|}{\dim\rho}\langle\psi,\chi_{\rho^v}\rangle$

\proof
\,

\begin{enumerate}

\item First, $\gamma_\psi:\rho\to\rho$ is a homomorphism of $G$-representations, which follows from $\gamma_\psi\cdot g \cdot v = g\cdot \gamma_\psi\cdot v$ for all $g \in G, v \in \rho$, as $\gamma_\psi\in Z(k[G])$.

\item By Schur, $\gamma_\psi:\rho\to\rho$ is a scalar. 

\item $\gamma_\psi = \frac{\tr(\gamma_\psi|\rho)}{\dim\rho}\cdot\Id_\rho$, so
\[
\tr(\gamma_\psi|\rho) = \tr(\sum_{g\in G}\psi(g)e_g|\rho) = \sum_{g\in G}\psi(g)\chi_\rho(g) = |G|\langle\psi,\bar{\chi_\rho}\rangle = |G| \langle\psi, \chi_{\rho^v}\rangle
\]

\end{enumerate}

\qed

Now, consider $\gamma_\psi:k[G]\to k[G]$. This is zero as $\gamma_\psi$ acts as zero on every irrep (because it pairs to zero with all the irreps), and because it sends $1$ to $\gamma_\psi$, $\gamma_\psi$ has to be zero. 

\qed

\cor(of earlier claim)

$\frac{\dim\rho_i}{|G|}\gamma_{\chi_{\rho_i^v}}$ acts as $1$ on $\rho_i$, and 0 on $\rho_j$, for $\rho_i\neq\rho_j$ are irreps. 

\proof

\qed

\cor

Given any $V = \oplus\rho_i^{\oplus n_i}$, 
\[
\frac{\dim\rho_i}{|G|}\gamma_{\chi_{\rho_i^v}}
\]
acts as a projection onto $\rho_i^{n_i}\subseteq V$, which is called the $\rho_i$ isotypic part of $V$. 

\cor

$\#$irreps of $G = \#$conjugacy classes of $G$

\proof

Let $\{\rho_i\}$ be the irreps of $G$ (up to conjugacy (i.e isomorhpism)). 

Then $\{\chi_{\rho_i}\}$ is a basis for $Cl(G)$, so $\#$ of irreps = $\dim_kCl(G) = \#$conjugacy classes of $G$.

Remark: These two numbers are equal, but there is no natural or canonical bijection between the two sets in general.

\section*{\underline{Classifying rep'ns}}

\thm $G$ is abelian iff all irreps of $G$ are 1-dimensional.

\proof

Let $V$ be an irrep. If $G$ is commutative, then $\cdot g :V\to V$ is a $G$-homomorphism for all $g\in G$. 

By Schur, each $g \in G$ acts as a scalar. Now every subspace of $V$ is a subrep, hence $V$ is 1-dimensinoal. 

Now suppose that all irreps are 1-dimensional. Let $n_i$ be the dimensions of the irreps $\rho_i$, and let $c$ be the number of conjugacy classes (or equivalently the number of irreps) of $G$. Then $|G| = \sum_in_i^2$, but this is at least $c$, because we are taking the sum of $c$ positive numbers, but each $n_i$ is 1, so each element of $G$ is its own conjugacy class. 

\qed

\exm

Take $G = \Z/n\Z$

For each element $\zeta \in \mu_n \eqdef $nth roots of unity, consider $\chi_\zeta:\Z/n\Z \to k^*, a \mapsto \zeta^a$

This gives $n$ distinct reps, which is the number of conjugacy classes, hence we have a complete list. 

\exm

$S_3$ has conjugacy classes $[e], [(12)], [(123)]$, so there are 3 irreducible representations. We have a trivial representation, whose character sends all conjugacy classes to 1. 

We also have $sgn:S_3\to\{\pm1\}\subseteq k^*$, so $\chi_{sgn}$ sends $[e]$ to 1, $[(12)]$ to -1, and $[(123)]$ to 1. 

At this point we know there must be a third representation, $std$, and we can fill in its row in the character table somehow. $std$ is given by $S_3 \curvearrowright \C^{\{1,2,3\}}/\begin{pmatrix} 1 \\ 1 \\ 1 \end{pmatrix}$, with $\chi_{std} = \chi_{\C^{\{1,2,3\}}} - \chi_{triv}$, so $\chi_{st}(e) = 2, \chi_{std}(12) = 0, \chi_{std}(123) = -1$. 

We claim that $\chi_{std}$ is irreducible. To see this, we compute 
\[
\langle\chi_{std},\chi_{std}\rangle=\frac{1}{6}(2^2 + 3*0^2 + 2(-1)^2) = 1. 
\]

\exm

$Q_8 = \langle \pm1,\pm i,\pm j, \pm k\rangle$, with multiplication given as in the quaternion group, $i^2 = j^2 = k^2 = ijk = -1$. 

Conjugacy classes: $(e)$,$-1$, $\{\pm i\}$,$\{\pm j\}$,$\{\pm k\}$. 

$\chi_{triv}$ sends them all to 1, of course. 

\section*{Lecture 5, 21/1/25}

\begin{center}
\begin{tabular}{ c| c c c c c }
 & 1 & -1 & \{i, -i\} & \{j,-j\}&\{k,-k\} \\
\hline
triv & 1 & 1 & 1 & 1 & 1 \\
i-ker & 1 & 1 & 1 & -1 & -1 \\
j-ker & 1 & 1 & -1 & 1 & -1 \\
k-ker & 1 & 1 & -1 & -1 & 1 \\
$?$ & $\cdots$&$\cdots$ &$\cdots$ &$\cdots$ &$\cdots$  \\
\end{tabular}
\end{center}

Let $\mathbb{H} = \R\langle 1, i, j, k \rangle$. Then $Q_8 \curvearrowright \mathbb{H}$ by left multiplication, $\mathbb{H} \curvearrowleft \C$ by multiplication by $i$ on the right. This example might be useful to think about for the homework. 

Now let's get the character table for $S_4$. 
\begin{center}
\begin{tabular}{c | c c c c c}
\text{conj class} & 0 & (12) & (123) & (12)(134) & (1234) \\
\text{size} & 1 & 6 & 8 & 3 & 6 \\
\hline 
sgn & 1 & -1 & 1 & 1 & -1 \\
$std = \C^4/\begin{pmatrix}1\\1\\1\\1\end{pmatrix}$ & 3 & 1 & 0 & -1 & - 1 \\
$std\otimes sgn$ & 3 & -1 & 0 & -1 & 1 \\
$std\circ\pi_{4\to3}$ & $\cdots $ & $\cdots$ & $\cdots$ & $\cdots$ & $\cdots$ 
\end{tabular}
\end{center}
If $S_4$ is the symmetries of a tetrahedron, then $\pi_{4\to3}$ is the map from $S_4$ to $S_3$ furnished by $S_4$ acting on pairs of sides, of which there are 3. 

\underline{How does the structure of $G$ interact with its representation theory?}

\prop(Homework) 

Let $G, H$ be groups, (NOT necessarily finite!), $k = \bark$ algebraically closed.

Then any irrep of $G\times H$ has the form $V\boxtimes W$, where
\begin{itemize}

\item $V$ is an irrep of $G$,

\item $W$ is an irrep of $H$

\item $(g,h)\cdot v\boxtimes w = (g\cdot v)\boxtimes (h\cdot w)$

This is the same as tensoring the two reps of $G\times H$ we get from 
\[
\begin{tikzcd}
& G \ar[r] & \GL(V) \\
G\times H \ar[ur] \ar[dr] & & \\
& H \ar[r] & \GL(W) \\
\end{tikzcd}
\]

\end{itemize}

\proof

HW

\qed

We have now classified (modulo the homework) all representations of all finite abelian groups. 

In some sense, (the sense of Artin's theorem) is that the representation theory of a group is controlled by the rep theory of its abelian subgroups. 

\underline{Restriction \& induction}

Let $H \subseteq G$ be a subgroup of $H$, $G$ again finite. 

We have a restriction functor $Res_H^G: Rep_G\to Rep_H$, 
\[
(\rho:G\to\GL(W)) \mapsto \rho|_H
\]
There is a functor going the other way called induction, $Ind_H^G:Rep_H\to Rep_G$. 

\defn

Let $V$ be an $H$-representation. Then 
\[
Ind_H^GV \eqdef k[G]\otimes_{k[H]}V
\]

Equivalent descriptions: 

\[
Ind_H^G(V) \eqdef \{\phi:G\to V \mid \phi(gh^{-1}) = h\phi(g)\forall g \in G, h \in H\}
\]

An element of the former looks like $\sum_g e_g\otimes v_g$. Take $e_ge_h\otimes v = e_g\otimes (h\cdot v)$, $g\cdot \phi = g\phi(g^{-1}-)$. Think about this and see how this makes the descriptions the same. One more description: 
\[
Ind_H^G(V) = \bigoplus_{g\in G/H}g_i\cdot V
\]
where $g\cdot \sum g_iv_i = \sum g_{j(i)}k_i \cdot V $ where $g_jg_i = g_{j(i)}$ (???)

Exercise: check the above is equivalent to the other two things. 

\exm
\,
\begin{enumerate}

\item $Ind_H^G triv = k^{G/H}$ follows from second description. By definition, $Ind_H^Gtriv = \{f:G\to k\mid f(gh^{-1}) = h\cdot f(g) = f(g)\} = \{f:G/H\to k\}$

\item $Ind_{(1)}^Gk = k[G] \otimes_kk = k[G]$

\item Suppose $\chi:H\to\C^\times$ is a representation. What is $Ind_H^G\chi$? To find $Ind_H^G\chi(g)$, pick coset representative $g_i$ from $G/H$, and we get permutation matrix for $G\curvearrowright G/H$ times the diagonal matrix whose $i$th entry is $\chi(h_i)$, where $gh_i^{-1} = g_{j(i)}h_i^{-1}$
\end{enumerate}

\section*{Lecture 6, 23/1/25}

Corrections:

In the homework, problem 4 part a) should include the assumption that the action of $G$ on $H$ by conjugation is inner, i.e. for all $g \in G$, the map $(\cdot)^g:H\to H$ sending $h \mapsto g h g^{-1}$ is $(\cdot)^{h'}$ for some $h' \in H$. 

Remark: An example is if we take $G = A\times B, H = A\times\{1\}$. Then $(\cdot)^{(a,b)} = (\cdot)^{(a,1)}$

Last time:
\begin{itemize}

\item We did character tables for $Q_8,S_4$ 

\item We stated the classification of irreducible representations of a product $G\times H$

\item Classification of irreps of finite abelian groups

\item Restriction \& induction

\end{itemize}

Here is more on induction: 

$\Ind_H^G(V) \eqdef k[G]\otimes_{k[H]}V$, where $k[G]$ is a right module and $V$ is a left one. Tensoring a right with a left yields an abelian group (indeed a $k$-vector space), and it all works out because $k[G]$ is a left $k[G]$ module. 

It is also the set $\{\phi:G\to V \mid \phi(gh^{-1}) = h\cdot\phi(g)$ for all $g \in G, h \in H\}$, where 
\[
g\cdot\phi = \phi(g^{-1}\cdot)
\]

\underline{Explanation}

An element of $k[G]\otimes_{k[H]}V$ is a formal sum $\sum e_g\otimes v_g$ such that $e_ge_h\otimes v = e_g\otimes(h\cdot v)$

How to recognize induced representations:

\begin{itemize}

\item Suppose $V$ is a $G$-rep, $W \subseteq V$ is $H$-stable. When is $V \simeq \Ind_H^GW$?

\item Consider $gW\subseteq V$. Because $W$ is $H$-stable, this only depends on $[g]\in G/H$

\end{itemize}

\prop 

$V = \Ind_H^GW$ if and only if $V = \oplus_{g\in G/H}gW$

\proof

Sketch

Recall the third version, $\Ind_H^GV = \oplus_{g_i\in G/H}g_iU$

\qed

\prop

\begin{align*}
\chi_{\Ind_H^G\rho}(u) & = \frac{1}{|H|} \sum_{g\in G, g^{-1}ug \in H}\chi_\rho(g^{-1}ug) \\
& = \sum_{x\in G/H}\hat{\chi}_\rho(x^{-1}ux)\\
\end{align*}

where $\hat{\chi}_\rho(v) = \begin{cases} \chi_\rho(v) & v \in H \\ 0 & \text{ otherwise } \\ \end{cases}$

\proof

\qed

\prop 

Let $H \subseteq G$ be a subgroup of finite index. Then 
\[
\Hom_G(\Ind_H^GV,W) \simeq \Hom_H(V, \Res_G^HW)
\]

\proof

This is a special case of the tensor-hom adjunction: 
\begin{align*}
\Hom_G(\Ind_H^GV,W) & \simeq \Hom_G(k[G]\otimes_{k[H]}V, W) \\
& = \Hom_H(V,\Hom_G(k[G],W)) \\
& = \Hom_H(V, \underbrace{W}_{ \text{as an H-rep}} )\\
& = \Hom_H(V,\Res_G^HW)
\end{align*} 

\qed

\cor

Let $V$ be a representation of $H$, $W$ is a representation of $G$, both finite. Then 
\[
\langle \chi_{\Ind_H^GV},\chi_W\rangle = \langle \chi_V, \chi_{\Res_G^HW}\rangle
\]

\proof

These numbers are the dimensions of the hom-spaces, which are the same by the above. 

\qed

\thm[Artin]

Let $G$ be a finite group, $k = \bark, char k = 0$. Then the map
\[
\bigoplus_{H\subseteq G \text{cyclic}}Cl(H)\onto Cl(G)
\]
For each cyclic group $H$, it acts on characters linearly, so we can extend that to $Cl(H)$, and we can extend that to $\oplus Cl(H)$
\proof

Remark: Let $G$ be a finite group, $R(G)$ be the ``representation ring of $G$", 
\[
R(G) = \oplus_{\rho_i\text{ irreps of }G}\Z[\rho_i]
\]

with $[\rho_i]\cdot[\rho_j] = [\rho_i\otimes\rho_j]$, by writing $\rho_i\otimes\rho_j = \bigoplus_{\rho_k\text{ irreps }}\rho_k^{n_k}$

\prop

There is a map $R(G) \to Cl(G)$ sending $[\rho_i] \to \chi_{\rho_i}$. This is a ring homomorphism (because character of tensor product is pointwise product of characters).

There is an induced map $R(G) \otimes_{\Z}k \to Cl(G)$ which is an isomorphism. 

\proof

\,
\begin{enumerate}

\item These are vector spaces of the same dimension

\item The map is surjective because (for example,) characters of irreps span. 
\end{enumerate}

\qed

\cor[to Artin's theorem]

The map (linear extension of $\oplus\Ind_H^G$)
\[
\bigoplus_{H\leq G\text{ cyclic }}R(H)_k\to R(G)_k
\]
is surjective.

I.e. every representation of $G$ is a ``k-linear combo" of irreps induced from cyclic subgroups. 

\cor
\,
\begin{enumerate}

\item $\oplus_{H\leq G\text{ cyclic }} R(H)_\Q\to R(G)_\Q$ is surjective, i.e. every irreducible character of $G$ is a $\Q$-linear combination of characters induced from cyclic subgroups.

\item $\oplus_{H\leq Q \text{ cyclic }}R(H)\to R(G)$ has finite cokernel.

\end{enumerate}

\proof
\,
\begin{itemize}

\item $(1)\implies(2)$ because the image of $\Ind$ spans $R(G)$ rationally by (1), i.e. given $x \in R(G)$, there is $N$ such that $N\cdot x \in \Im(\Ind)$, so the cokernel is torsion, and torsion finitely generated abelian groups are finite. 

\item We know $(1)$ by Artin, because $\Ind_\Q\otimes_\Q k$ is surjective, as rank $r$ invariant under extension of scalars?

\end{itemize}

\qed

We now prove Artin's theorem:

\proof

It is enough to show that the adjoint map of $\oplus\Ind_H^G$ is injective. But $\langle \Ind \chi, \psi \rangle = \langle \chi, \Res \psi \rangle$, so 
\[
\bigoplus\Res_G^H :Cl(G) \to \bigoplus_{H\leq G\text{ cyclic }}Cl(H)
\]
is adjoint to $\Ind$. Now let $\psi$ be in the kernel; then $\Res_G^H\psi \equiv 0$ for all $H$, which implies $\psi \equiv 0$, so we win. 

\qed

\subsection*{\underline{Loose ends:}}

\begin{itemize}

\item Structure of $k[G]$

\item Integral theory

\item Corollary of all this discussion: if $G$ is a finite group, $\rho$ an irrep, then $\dim\rho \mid |G|$

\end{itemize}

\subsection*{\underline{Structure of $k[G]$ (and more generally, semisimple algebras)}}

\defn

Let $k$ be a field, $R$ a $k$-algebra (possibly non-commutative). Then $R$ is \underline{semisimple} if 
\,
\begin{enumerate}

\item $R$ is finite dimensional as a $k$-vector space

\item All left $R$-modules which are finite-dimensional $k$-vector spaces are semisimple. 

\end{enumerate}

\thm

Let $R$ be semisimple $k$-algebra. Then 
\[
R \simeq \prod\Mat_{n_i}(D_i)
\]
where $D_i$ are division $k$-algebras.

\proof (Take $R = k[G]$)

Conside $R$ as a left $R$-module;
\[
R \simeq \oplus M_i^{\oplus n_i}
\]
where $M_i$ is simple, all $M_j$s are mutually non-isomorphic left $R$-modules.

 Note $\Hom_{\Rmod}(M_i,M_i)$ is a division algebra (otherwise we would have a morphism with a kernel, but $M_i$ is simple). 

Because $R^{op} \simeq \Hom_{\Rmod}(R,R)$, this means 
\[
R \simeq \Hom_{\Rmod}(\oplus M_i^{\oplus n_i}, \oplus M_i^{\oplus n_i})
\]

Now, $\Hom_{\Rmod}(M_i,M_j) = 0$ for $i \neq j$ (again by simplicity and mutual nonisomorphicness) so 
\[
\Hom_{\Rmod}(R,R) \simeq \oplus_i \Hom_{\Rmod}(M_i^{n_i},M_i^{n_i})
\]

So if we take $D_i^{op} = \Mat_{n_i}(\Hom(M_i,M_i))$, we win. 

\qed

\cor

Let $k = \bark$. Then $R \simeq \oplus \Mat_{n_i}(k)$

\proof
\,
\begin{enumerate}

\item Finite dimensional central division algebras over an algebraically closed field are the field itself. 

\item Or, same proof as in Schur, 
\[
\Hom_{\Rmod}(M_i,M_i) = k
\]

\end{enumerate}

\qed

Let's specialize to $R = k[G]$. 

As a $k[G]$-module, $k[G] \simeq \rho_i^{\oplus n_i}$, so we have a map
\[
k[g]\to\bigoplus_{\rho_i\text{ irrep }} \underline{\Hom}_k(\rho_i,\rho_i) \simeq \oplus_{\rho_i\text{ irrep }}\rho_i\boxtimes\rho_i^v \simeq \oplus_{\rho_i\text{ irrep }}\rho_i\otimes\Hom(\rho_i,k[G])
\]
\[
x \mapsto \text{right multiplication by } x
\]

Recall: If $V$ is any $G$-rep, then $V = \oplus \rho_i\otimes\Hom_G(\rho_i,V)$, 

so we have $k[G] \to \oplus \End(\Hom(\rho_i, k[G]))$

\claim

This isomorphism of rings is $G\times G$-equivariant if we give $\End(\rho_i^{\dim\rho_i})$ the $G\times G$ structure $\rho_i\boxtimes\rho_i^v$

\proof

We need to check $\End(\rho_i^{\dim_i})$ as a right $G$-module it is $(\rho_i^v)^{\dim \rho_i}$.

If $G \into G\times G$ by $g\mapsto (g, g^{-1})$, then it has an invariant in $\Hom_G(\rho_i^{\dim \rho_i},\rho_i^{\dim\rho_i})$, 

As $G$-reps, $\Hom(\rho_i,\rho_i) \simeq \rho_i\otimes\rho_i^v$

\claim

Given a rep $V\boxtimes W$ of $G\times G$, the structure of $V$ and $V\boxtimes W|_{(g, g^{-1})}$ determines $W$.

\proof

\qed

\section*{Lecture 7, 28/1/25}

Substitute for today: Dr Jacob Tsimerman

Let $k = \bark$ be an algebraically closed field of characteristic $0$, $G$ a finite group. 

Let $(\rho_1,V_1), \dots, (\rho_n,V_n)$ be the irreducible left representations of $G$. 

\thm
\[
k[G] \cong \bigoplus_{i=1}^n\rho_i\boxtimes\rho_i^v = \bigoplus_{i=1}^nV_i\otimes V_i^*
\]
as $G\times G$-reps $((g,g')\cdot v\otimes v^* = (g\cdot v)\otimes v^* + v\otimes (g'\cdot v^*))$

\proof

Let $W_i \eqdef \Hom_G(V_i, k[G])$. Then 
\[
k[G] \cong \bigoplus_{i=1}^nV_i\otimes W_i
\]
as $G\times G$-representations because we get the right $G$-action for free. 

\claim

As right $G$-representations, $W_i \cong V_i^*$

\proof
\,

\underline{Convention:} Given an element $x = \sum_{g\in G}a_g(x)g \in k[G]$, we use $a_g:k[G] \to k$ to denote the $g$-th coefficient. 

This has the property that $a_g(x\cdot g') = a_{g'g^{-1}}(x)$

Define $\psi:W_i \to V_i^*$ by 
\[
\psi(\phi)\eqdef a_1\circ\phi
\]

\claim

$\psi$ is an isomorphism

\proof

Suppose $\phi\in W_i$. For $g \in G$, $a_g(\phi(v)) = a_1(g^{-1}\phi(v))$. But $\phi$ is a map of left $G$-modules, so this is $a_1(\phi(g^{-1}(v))) = \psi(\phi)(g^{-1}v)$. 

So, we can write
\[
\phi(v) = \sum_{g\in G}\psi(\phi)(g^{-1}v)\cdot v
\]
 
So $\phi$ is entirely determined by $\psi(\phi)$, or in other words, $\psi$ is injective.

On the other hand, let $\ell \in V^*$. 

Consider $\phi_\ell \in W_i$, $\phi_\ell(v) = \sum_{g\in G}\ell(g^{-1}v)\cdot g$

\claim

$\phi_\ell \in W_i$

\proof

Let $g_0 \in G$. Then 
\[
\phi_\ell(g_0v) = \sum_{g\in G}\ell(g^{-1}g_0v) = \sum_{g\in G}\ell(g^{-1}v)\cdot g_0g = g_0\cdot\phi_\ell(v)
\]

This shows that $\psi$ is surjective.

\qed

\claim

$\psi$ respects the right $G$-action. 

\proof

\begin{align*}
\psi(\phi^{g_0})(v) & = \psi(\phi)(g_0v) \\
& = a_1(\phi(g_0v))\\
& = a_1(g_0\phi(v)) \\
& = a_{g_0^{-1}}(\phi(v)) \\
\end{align*}

On the other hand, 
\begin{align*}
\psi(\phi^{g_0}v) & = a_1(\phi^{g_0}(v)) \\
& = a_1(\phi(v)g_0) \\
& = a_{g_0^{-1}}(\phi(v))
\end{align*}
So $\psi(\phi^{g_0}) = \psi(\phi)^{g_0}$
\qed

This proves the theorem. 
\qed

\underline{Matrix Coefficients}

Let $\{v_1, \dots, v_n\}$ be a basis for an irreducible representation $V$. 

Let $\{v_1^*, \dots, v_n^*\}$ be the dual basis for $V^*$.

\defn

Given $1 \leq i, j \leq m$, the \underline{matrix coefficient $a_{i,j}$} is given by 
\[
a_{i,j}(g) = v_i^*(g\cdot v_j)
\]
This is a function from $G$ to $k$. 

Define $A_{i,j} \in k[G]$ by 
\[
A_{i,j}\eqdef \sum_{g\in G}a_{i,j}(g)\cdot g 
\]

\thm
\[
\langle A_{i,j}\rangle_{1\leq i, j\leq m} = \rho\boxtimes\rho^v
\]
where $(\rho,V)$ is the $G$-rep.

\proof

\qed

\thm

Let $G$ be a finite group, $k = \bark$ an algebraically closed field of characteristic 0. 

Let $(\rho,V)$ be an irreducible representation of $G$. 

Then $\dim V \mid |G|$

\proof

\cor

If $d_1, \dots, d_n$ is the dimensions of the irreps of $G$, then 
\begin{enumerate}

\item $m = $number of conjugacy classes of $G$ (often called $m$)

\item $d_i | |G|$ for all $i$

\item $\sum_{i=1}^m d_i^2 = |G|$

\end{enumerate}

\proof

\qed

\exm

If $G = S_3$, $m = 3$, with conjugacy classes $[\Id], [(12)],[(123)]$, then we have $d_1 = 1, 1 + d_2^2 + d_3^2 = 6, d_2, d_3 \mid 6$. 

So we must have $d_2 = 1, d_3 = 2$. 

\underline{Recollections of algebraic integers}

\defn

Let $R$ be a commutative ring. 

Then $x \in R$ is \underline{integral}, or an \underline{algebraic integer}, if $x$ satisfies a monic integer polynomial. 

\exm
\,
\begin{itemize}

\item 3

\item $\sqrt{5}$

\item $\frac{1+\sqrt{5}}{2}$

\end{itemize}

Non-examples include
\begin{itemize}

\item $\frac37$

\item $\frac{1}{\sqrt{2}}$

\end{itemize}

\prop

The following are equivalent:\,
\begin{enumerate}

\item $x$ is integral

\item The subring generated by $x$ is a finitely generated $\Z$-module

\item The subring generated by $x$ is contained in a finitely generated $\Z$-module in $R$. 

\end{enumerate}

\proof

Let's start with $(1)\implies(2)$. 

Suppose $x^N + \sum_{i=1}^{N-1}a_ix^i = 0$, $a_i \in \Z$. 

Then $x^N \in \langle1,x,\dots,x^{N-1}\rangle_\Z$. But then $x^{N+1} \in \langle 1, x, \dots, x^N\rangle_\Z$, so $x^{N+1} \in \langle 1, x, \dots, x^{N-1}\rangle_\Z$.

So the subring generated by $x$ equals $\langle 1, x, \dots, x^{N-1}\rangle_\Z$.

$(2)\implies(3)$ is clear

So let's see $(3)\implies(1)$. 

Let $A_N = \langle 1, x, x^{N-1}\rangle_\Z$. By assumption, there exists a finitely generated $\Z$-module $B \subset R$ such that $A_1\subseteq A_2 \subseteq\cdots \subseteq B$ 

By Noetheriality, the sequence stabilizes, so there exists some $M$ such that $A_M = A_{M-1}$, and so $x^M$ is a finite linear combination of lower powers of $x$, so there are $a_i$ such that
\[
x^M + \sum_{i=1}^{M-1}a_ix^i = 0
\]

\cor

The things on the list of non algebraic integers actually belong on the list!

\proof

\qed

\section*{Lecture 8, 30/1/25}

Sub Prof: Mathilde Gerbelli-Gauthier

End Goal: $G$ finite, $\rho$ irrep of $G$ over $k = \bark$ algebraically closed of characteristic 0. We want to show that $\dim \rho \mid |G|$

Strategy: Prove that $\frac{|G|}{\dim\rho}$ is an algebraic integer

As a corollary of the proof of the last prop, we get

\cor

Integral elements of $R$ form a subring. 

\proof

\qed

\subsection*{\underline{Integrality of characters}}

As always, let $G$ be a finite group, $k = \bark$ algebraically closed of characteristic 0, and $\rho:G\to\GL_n(k)$ just any representation (not necessarily irreducible).

\prop
\,
\begin{enumerate}

\item The values of the character of $\rho, \chi_\rho(g)$, are algebraic integers

\item Let $u = \sum_{g\in G}u(g)g$ be an element of $Z(k[G])$. Suppose that $u(g) \in k$ are algebraic integers. Then $u$ is integral. 

\end{enumerate}

At some point in the classes I missed we show that the indicators of conjugacy classes span the center of $k[G]$. 

\proof
\,
\begin{enumerate}

\item $\chi_\rho(g)$ is a sum of roots of unity, hence a sum of algebraic integers, hence an algebraic integer.

\item Using a previous result, let $u(g)$ be the indicator function of a conjugacy class. But the sub-$\Z$-module of $Z(k[G])$ generated by the indicator functions is a subring (because the product of $1_{C_1}\cdot 1_{C_2}$ is a linear combination of the indicators of conjugacy classes, and the coefficient in front of each $g$ is an integer). 

Thus each indicator of a conjugacy class is contained in a finitely generated $\Z$-module, and is integral. 

\end{enumerate}

\qed

\cor

Let $\rho$ be an irrep of $G$ and let $u \in Z(k[G])$ be as before. Then
\[
u_\rho = \frac{1}{\dim\rho}\sum_{g\in G}u(g)\chi_\rho(g) \in k
\]
is an algebraic integer. 

\proof

\claim

Given $\rho$, $u \mapsto\frac{1}{\dim\rho}\sum u(g)\chi_\rho(g)$ is a ring homomorphism

\proof

\[
u_1 * u_2 \mapsto \left(\frac{1}{\dim\rho}\sum u_1(g)\chi_\rho(g)\right)\left(\frac{1}{\dim\rho}\sum u_2(g)\chi_\rho(g)\right)
\]

\qed

The goal will be to define a ring-hom from $Z(k[G])$ to $k$ sending $u$ to $u_\rho$. Since $u$ is integral , it maps to to an integral element of $k$. 
\[
u \mapsto \frac{|G|}{\dim\rho}\langle u, \chi_{\rho^v}\rangle = u_\rho
\]
\[
\sum u'(g)\chi_\rho(g) = |G|\langle u, \rho^v\rangle
\]

Recall that $Z(k[G]) \curvearrowright\rho$ by $G$-homomorphism, that action induces a natural map 
\[
Z(k[G]) \mapsto \Hom_G(\rho,\rho) = k
\]
So
\[
u \mapsto \frac{|G|}{\dim\rho}\langle u,\chi_{\rho^v}\rangle
\]
The matrix is scalar, so it suffices to compute its trace. Its trace is 
\[
\sum_{g\in G} u(g)\chi_{\rho}(g) = |G|\langle u,\chi_{\rho^v}\rangle
\]
Dividing by $\dim\rho$ gives the result. 

\qed ?

\thm

Let $G$ be a finite group, $k = \bark$ an algebraically closed field of characteristic 0, $V_\rho$ an irrep of $G$. Then $\dim V \mid \|G|$

\proof

Set $u = \sum_{g\in G}\chi_\rho(g^{-1})g$. By the above, we have 
\begin{align*}
\frac{1}{\dim\rho}\sum u(g)\chi_\rho(g) & = \frac{|G|}{\dim\rho}\langle\chi_{\rho^v},\chi_{\rho^v}\rangle \\
& = \frac{|G|}{\dim\rho}\underbrace{\dim\Hom_G(\rho^v,\rho^v)}_{=1} \\
& = \frac{|G|}{\dim\rho}
\end{align*}
But the left hand side is an integral element of $\Q$, so the right hand side is an integral element of $\Q$, hence an integer. 

\qed

\subsection*{\underline{Rep theory of the symmetric group}}

As always, $|G|<\oo, Char (k = \bark) = 0$

Here are some key facts about the symmetric groups: 
\begin{enumerate}

\item The number of irreps of $S_n$ is equal to the number of conjugacy classes in $S_n$. 

\item The conjugacy classes in $S_n$ (aka cycle type) are in bijection with partitions of $n$. 

\item The irreps of $S_n$ are also indexed by partitions of $n$. 

\end{enumerate}

\defn

A \underline{partition of $n$} is a sequence $\lambda = (\lambda_1 \geq \lambda_2 \geq \cdots \geq \lambda_r)$ such that $\sum\lambda_i = n$. 

\defn

The \underline{young diagram} $D_\lambda$ has $\lambda_1$ boxes in the first row, $\lambda_2$ in the second row, etc.

For example, the corresponding diagram for $\lambda = (4,3,1)$ 
\[
\ytableausetup{centertableaux}
\begin{ytableau}
\,& & & \\
& &  \\
& \\
\end{ytableau}
\]

The conjugate partition $\lambda'$  is the one such that $D_{\lambda'}$ is obtained by $D_\lambda$ by flipping along the diagonal. 

If $\lambda = (4,3,1), \lambda' = (3,2,2,1)$. Then $D_{\lambda'}$ is

\[
\ytableausetup{centertableaux}
\begin{ytableau}
\,& & \\
& \\
& \\
\\
\end{ytableau}
\]

\subsection*{\underline{Proejctions and young symmetrizers}}

An algorithm: start with $\lambda$

\begin{enumerate}

\item Number the booxes in your Young diagram $D_\lambda$ from left to right, top to bottom: you now have a young tableaux. 
\[
\ytableausetup{centertableaux}
\begin{ytableau}
1 & 2 & 3 & 4 \\
5 & 6 & 7 \\
8
\end{ytableau}
\]

\item Let $\cdot P \subseteq S_n$ be the subgroup of all permutations that preserve each row of our Young tableaux. E.g. $P \simeq S_4\times S_3 \into S_8$. 

\item $Q \subseteq S_n$ the subgroup that preserves each column of the same Young tableau e.g. $Q \simeq S_3 \times S_2 \times S_2 \into S_8$. 

In $\C[S_n]$, define $a = \sum_{p\in P}e_p, b = \sum_{q\in Q}sgn(q)e_q$

\item Suppose that $V$ is a vector space, and $S_n \curvearrowright V^{\otimes n}$ by permuting factors. 

The element $a$ symmetrizes along the rows, and projects onto 
\[
Sym^{\lambda_1}(V) \otimes \cdots \otimes Sym^{\lambda_n}(V)
\]
up to an isomorphism.

\item The element $b$ alternates along the columns and projects onto a tensor product of exterior powers indexed by $\lambda'$: 
\[
\bigwedge^{\lambda'_1}(V)\otimes \cdots \otimes \bigwedge^{\lambda'_n}(V)
\]

\item Set $c = ab$. This is called the \underline{Young Symmetrizer}

Here are some examples of Young symmetrizers:
If $\lambda = (1, \dots, 1)$, then $c$ gives the sign representation. $\lambda = (n)$ gives the trivial rep.

\end{enumerate}

\subsection*{\underline{Irreducibility and idempotency}}

\thm

A suitable nonzero scalar of $c = ab$ is an idempotent in $\C[S_n]$. Its image, when acting on the regular representation, is irreducible, and denoted $V_\lambda$.

Distinct partitions give rise to distinct (meaning nonisomorphic) representations and every irep arises from this process for a unique partition.

\cor

Every representation of $S_n$ is defined over $\Q$.

\proof

\qed

\exm
\,
\begin{itemize}

\item For $S_3$, $triv = (4), sgn = (1,1,1), std = (2,1)$ 

\item For $S_4$, $triv = (4), sgn = (1,1,1,1), std = (3, 1), std \otimes sgn = (2,1,1), S_4 \to S_3 = (2,2)$ 

\item In general, $(d,1,\cdots,1)$ corresponds to various exterior powers of the standard representation.

\end{itemize}

\thm(Hook-length formula)

Label each box $b$ in a young diagram (boxes to the right of $b$) $+$ (boxes below). 

These are called hook lengths. Then $\dim V_\lambda = \frac{n!}{\prod (\text{hook lengths of $b$})}$

\proof

\qed

\section*{Lecture 9, 4/2/25}

Let $n \in \Z_{>0}$. Our goal is to classify irreps of $S_n$. Recall:

\thm

For each partition $\lambda$ of $n$, there exists a unique isomorphism class of irrep $V_\lambda$ of $S_n$, constructed as follows: 
\[
\ytableausetup{centertableaux}
\begin{ytableau}
\,& & & & & \lambda_1 \\
& & & \lambda_2 \\
& & \lambda_3 \\
& \lambda_4 \\
\end{ytableau}
\]
where $\sum\lambda_i = n$
We let $R$ be the subgroup of $S_n$ which preserves the rows, $Q$ the subgroup preserving the columns. We set
\[
a\eqdef \sum_{g\in P}e_g \in \C[S_n]
\]
\[
b\eqdef \sum_{g\in Q}sgn(g)e_g \in \C[S_n]
\]
\[
c = ab
\]
Then $V_\lambda \eqdef \C[S_n]c$ is an irrep of $S_n$. 

Further, every irrep arises in this way. 

\proof

Summary: \, WTS
\begin{enumerate}

\item $\dim\Hom_G(V_\lambda,V_\mu) = \delta_{\mu\lambda}$

\item Any irrep is some $V_\lambda$.

\end{enumerate}

\underline{Remark:}
\,
\begin{enumerate}

\item There is an explicit dimension formula, the hook-length formula

\item There is an explicit formula for the character of $V_\lambda$ due to Frobenius. 

\end{enumerate}

For more, look for Etingof's ``Representation theory" notes for a course given at MIT. 

We will begin the proof by writing down $c_\lambda$. 

\lem

\[
c_\lambda = \sum_{g = \underbrace{p}_{\in P_\lambda}\underbrace{q}_{\in Q_\lambda}}sgn(q)e_{pq}
\]
\proof
\begin{align*}
a_\lambda b_\lambda & = \left(\sum_{g\in P_\lambda}e_g\right) \cdot \left(\sum_{h\in Q_\lambda}sgn(h)e_h\right)\\
& = \sum_{g\in P_\lambda, h \in Q_\lambda} sgn(h)\underbrace{e_ge_h}_{e_{gh}}
\end{align*}

\qed

Goal: Compute $c_\lambda^2 = a_\lambda b_\lambda a_\lambda b_\lambda$

\lem

For all $x \in \C[S_n]$, $a_\lambda x b_\lambda = \ell_\lambda(x)c_\lambda$, where $\ell_\lambda:\C[S_n]\to\C$ is some linear map. 

\cor

$c_\lambda^2 = \ell_\lambda(b_\lambda a_\lambda)c_\lambda$

\proof

Check this on each $e_g \in \C[S_n]$, $g \in S_n$. 
\begin{enumerate}

\item[Case 1] $g \in P_\lambda Q_\lambda$

We have $g = pq, e_g = e_pe_q$. 
\begin{align*}
a_\lambda e_g b_\lambda & = \left(\sum_{h \in P_\lambda}e_h\right) e_g \left(\sum_{u\in Q_\lambda}sgn(u)e_u\right) \\
& = \underbrace{\left(\sum_{h\in P_\lambda}e_he_p\right)}_{a_\lambda}\underbrace{\sum_{u\in Q_\lambda}sgn(u)e_qe_u}_{sgn(q)b_\lambda} \\
& = sgn(q)c_\lambda b_\lambda \\
& = sgn(q)c_\lambda
\end{align*}

\item[Case 2] $g \not\in P_\lambda Q_\lambda$

In this case, $a_\lambda e_g b_\lambda = 0$. To see this, it is enough to show that there exists a transposition $t \in P_\lambda$ such that $g^{-1}tg \in Q_\lambda$, i.e.  $g$ sends two elements of $\{1, \dots, n\}$ in the same row of the Young diagram for $\lambda$, to two elements of the same column. 

It is enough to show this because
\begin{align*}
a_\lambda gb_\lambda & = a_\lambda t g b_\lambda \\
& = a_\lambda g\overbrace{(g^{-1}tg)}^{sgn = -1}b_\lambda \\
& = -a_\lambda g b_\lambda \\
\end{align*}
This implies $a_\lambda gb_\lambda = 0$.

Now, suppose there do not exist 2 elements in the same row of $\lambda$ sent to the same column of $\lambda$ by $g$. 

Then $g \in P_\lambda Q_\lambda$.

To see this, let $T$ be the \underline{standard} Young Tableau for $\lambda,T' = gT$, $P'$ the stabilizer of rows of $T'$, $Q'$ the stabilizers of columns. 

\begin{enumerate}[label=(\roman*)]

\item By assumption, any two numbers in the first row of $T$ lie in different columns of $T'$.

\item Then there exists $q_1' \in Q'$ such that $q'T'$ has the same elements in first row (perhaps in a different order). 

\item Choose $p_1' \in P_\lambda$ such that $p_1'q_1'T'$ has the first row as $T$.

\item Likewise with the 2nd row and so on. 

\end{enumerate}


\end{enumerate}

\qed

\cor

\[
\ell_\lambda(b_\lambda a_\lambda) = \frac{n!}{\dim V_\lambda}
\]

\proof

later

\qed

\section*{Lecture 10, 6/2/25}

Note: For the finite group stuff we are using ``Linear reps of finite groups" by Serre (first 3rd is for chemists apparently which is amusing). Specifically chapters 1-3, 6, 9

Other stuff is also on the quercus. 

To finish the proof of the theorem, we have to show that the $V_\lambda$ are irreducible and mutually non-isomorphic. Then, from a bijection between conjugacy classes and partitions, we will be done. 

Last time we showed that $a_\lambda x b_\lambda = \ell_\lambda(x)c_\lambda$, and its corrolary, that $c_\lambda^2 = \ell_\lambda(b_\lambda a_\lambda)c_\lambda$

\cor

\[
\ell_\lambda(b_\lambda a_\lambda) = \frac{n!}{\dim V_\lambda}
\]

\proof

We know that $c_\lambda = \alpha \cdot p_\lambda$, where $p_\lambda$ is an idempotent. 
\begin{align*}
c_\lambda^2 & = \alpha^2p_\lambda^2 \\
& = \alpha^2 p_\lambda \\&= \alpha c_\lambda \\
\end{align*}
So $\alpha = \ell_\lambda(b_\lambda a_\lambda)$ so we calculate the trace of $c_\lambda:$
Trace of an idempotent is dim of its image, and $c_\lambda$ has the same image as $p_\lambda$
\begin{align*}
\tr(c_\lambda) & = \alpha\cdot\dim\Im(c_\lambda) \\
& = \ell(b_\lambda a_\lambda)\cdot\dim\Im(c_\lambda) \\
& = \ell(b_\lambda a_\lambda)\cdot \dim V_\lambda 
\end{align*}
Now, if this number is not zero, then we get an idempotent by dividing $c_\lambda$ by this number. We calculate
\begin{align*}
\tr(c_\lambda) & = \sum_{pq \in P_\lambda Q_\lambda} \tr(\cdot e_{pg})sgn(q) \\
& = \tr(\cdot\Id) \\
& = n!
\end{align*}

\qed

Goal: Compute $\dim_\C\Hom_{S_n}(V_\lambda, V_\mu) = \begin{cases} 1 & \lambda = \mu \\ 0 & \text{ otherwise } \\ \end{cases}$

We know $\Hom_{S_n}(V_\lambda,V_\mu)  = \Hom_{S_n}(\C[S_n]c_\lambda, \C[S_n]c_\mu)$

\prop

Let $A$ be a $\C$-algebra, $e \in A$ an idempotent, $M$ an $A$-module.

Then $\Hom_A(Ae,M) \simeq eM$ naturally. 

\proof

For $x \in eM$, we have a morphism $x \mapsto (a \mapsto ax)$, and $f \mapsto f(e)$. 

$e$ is an idempotent, so $1 - e$ is also an idempotent, so $1 = e + (1 - e)$, so $A \simeq Ae\oplus A(1-e)$, so $\Hom(Ae, M) \simeq \Hom(A/A(1-e),M)= \{f:A \to M \mid f(e) = f(1)\}=\{x\in M \mid x \in eM\} = eM$

\qed

Now let's prove the main theorem. 

\prop

\[
\dim_C\Hom_{S_n}(V_\lambda,V_\lambda) = 1
\]
Thus, $V_\lambda$ is irreducible

\proof

\begin{align*}
\Hom_{S_n}(V_\lambda,V_\lambda)&=c_\lambda \C[S_n]c_\lambda \\
& \subseteq a_\lambda \C[S_n]b_\lambda \\
& \subseteq \Span_{\C}(c_\lambda) \\
\end{align*}
So the dimension is at most 1. To see it is exactly 1, this space has $c_\lambda\cdot1\cdot c_\lambda \neq 0$

So $\dim = 1$, so $V_\lambda$ is irreducible.

\qed

Now let $\lambda,\mu$ be two partitions of $n$. Sat $\lambda > \mu$ if the first $\lambda_i \neq \mu_i$ has $\lambda_i > \mu_i$, i.e. the lexicographical ordering. This is a total ordering, i.e. for any pair $(\lambda,\mu)$, exactly one of $\lambda = \mu, \lambda > \mu, \lambda < \mu$ is true.

\prop

If $\lambda > \mu$, then $a_\lambda \C[S_n]b_\mu = 0$. 

\proof

In a bit

\qed

Assuming this, then, if $\lambda\neq\mu$, we want to show that $\dim\Hom_{S_n}(V_\lambda,V_\mu) = 0$.

\proof

We have 
\begin{align*}
\Hom_{S_n}(V_\lambda,V_\lambda) & = c_\lambda\C[S_n]c_\mu \\
& = a_\lambda b_\lambda \C[S_n]a_\mu b_\mu \\
& \subseteq a_\lambda \C[S_n]b_\mu \\
& = 0
\end{align*}
if $\lambda > \mu$. But $\dim\Hom_{S_n}(V_\lambda,V_\mu) = \dim\Hom_{S_n}(V_\mu,V_\lambda)$, so one, hence both, are 0. 

\qed

Now we prove the proposition

\proof

We will verify it on $e_g \in \C[S_n]$. 

\claim

There exist two numbers on the same row of the standard Young tableaux for $\lambda$, same column for $g\cdot($standard Young tableaux of $\mu$)

\proof

Homework

\qed

\exm

If $g = \Id, \lambda_1 > \mu_1$, 
\[
\ytableausetup{centertableaux}
\begin{ytableau}
\,1 & 2 & 3 & 4 \\
&  & \\
&  \\
\end{ytableau},
\ytableausetup{centertableaux}
\begin{ytableau}
\,1 & 2 & 3 \\
4 & 5 \\
& \\
\end{ytableau}
\]

Let $t$ be the transpotion for these two numbers. Then 
\begin{align*}
a_\lambda gb_\lambda & = c_\lambda t g b_\mu \\
& = a_\lambda gg^{-1}tgb_\lambda \\
& = -a_\lambda gb_\mu \\
\end{align*}

\subsection*{\underline{The rep theory of $\GL_2(\F_p)$}}

\underline{Goal:} Understand the irreps of $\GL_n(\F_q)$

What is the size of this group?

$|\GL_2(\F_q)| = (q^2 - 1)(q^2 - q) = q(q^2 - 1)(q - 1)$

\proof

\[
\GL_2(\F_q) = \{(v, w) \mid v, w \in (\F_q)^2\text{ linearly independent }\}
\]
So we can pick any $v$ a nonzero vector, and any $w$ not in the span of $v$. The number of such possible choices is $(q^2 - 1)(q^2 - q)$

\qed

\underline{Conjugacy classes:}

What are the conjugacy classes of $\GL_2(\F_q)$?




What are the reps of $\GL_2(\F_q)$ over $\C$? Besides the trivial one, we also have $P^1(\F_1) = \{1-dim$ subspaces of $\F_q^2\}$.

This gives a permutation representation $\C^{P^1(\F_q)}$.

We have $std = \C^{P^1(\F_q)}/\C$ has dimension $q$. Let's compute the character of this representation. Let's call the first set of conjugacy classes above $z_x$, the second $d_{x, y}$, $u_x$, $t_{x,y}$

\begin{center}
\begin{tabular}{c| c c c c}
\, &$z_x$ & $d_{x, y}$ & $u_x$ & $t_{x,y}$ \\
\hline
triv & 1 & 1 & 1 & 1 \\
std & $q$ & 1 & 0 & -1 \\
\end{tabular}
\end{center}
We have 
\begin{align*}
\langle std, std \rangle & = \frac{1}{q(q-1)^2(q+1)}\left((q-1)q^2 + \frac{q(q-1)(q-2)(q+1)}{2} + 0 + \frac{q^2(q-1)^2}{2}\right) \\
& = 1
\end{align*}

What other representation are there?

Choose $\chi:\F_q^\times\to\C$, and then $(\chi\circ\det)^n$, for $n = 1, \dots, q-2$.

To construct more reps, we will examine some induces reps. 

\defn

Let $B = \pmat{*}{*}{0}{*} \subseteq \GL_2(\F_q)$ ($B$ is for Borel)

$|B| = q(q-1)^2$. Let $U$ be all the matrices of the form $\pmat{1}{*}{0}{1}$. 

What is $B/U$? It is $\F_q^\times \times \F_q^\times$. We will take reps of this and view them as reps of $B$ via the quotient map and induced reps. 

For each $\psi:\F_q^\times\times\F_q^\times\to\C^\times$, we can consider the induction $\Ind_B^{\GL_2(\F_1)}(\psi|_B)$. These are indexed by $\psi(\epsilon,1)$ and $\psi(1,\epsilon)$. 

Then $\Ind_B^{\GL_2(\F_q)}(\psi_{a,b}|_B)$ has dimension $q+1$ and has character $(q+1)\psi(x)^2$

For $d_{x, y}$ we have $\psi(x,1)+\psi(1,x) + \psi(y,1) \cdot \psi(1,y)$

I have kind of lost the plot at this point I'm sorry.

\prop

Let $\chi = \sum n_i \rho_i \in R(G)$ be a virtual character of a finite group $G$. Then $\chi$ is the character of an honest irrep iff $\langle\chi,\chi\rangle = 1$, and $\chi(1)>0$. 

\proof

If we write $\chi = \sum n_i' \rho_i'$, where $\rho_i'$ are irreps, then $\langle\chi,\chi\rangle = \sum_i(n_i)^2 = 1$ by assumption. So at most one of the $n_i$ are nonzero, and it must be $\pm 1$. So $\chi = \pm\rho$ for some irrep $\rho$. If $\chi(1)>0$, then $\chi(1)= \pm\dim\rho>0$


\section*{Lecture 11, 11/2/25}

For simplicity, we will assume $q$ is odd (even is similar, but annoying to do uniformly)

Recall that $|\GL_2(\F_q)| = (q^2-1)(q^2-q)$

\begin{center}
\begin{tabular}{c | c | c}
Conjugacy class & number of such conjugacy classes & size of each \\
$\pmat{x}{0}{0}{x}, x \in \F_q^\times$ & $q- 1$ & 1 \\
$\pmat{x}{0}{0}{y}, x \neq y\in \F_q^\times$ & $\frac{(q-1)(q-2)}{2}$ & $q(q+1)$\\
$\pmat{x}{1}{0}{x}, x \in \F_q^\times$ & $q-1$ & $q^2 - 1$ \\
$\pmat{x}{\epsilon y}{y}{x},\epsilon$ a generator of $\F_q^\times$ & $\frac{q(q-1)}{2}$ & $q^2 - q$ \\
\end{tabular}
\end{center}
For the last one, $char\neq2$

\begin{center}
\begin{tabular}{c| c c c c}
\, &$z_x$ & $d_{x, y}$ & $u_x$ & $t_{x,y}$ \\
\hline
triv & 1 & 1 & 1 & 1 \\
std & $q$ & 1 & 0 & -1 \\
\end{tabular}
\end{center}

We denote by $B$ all matrices of the form $\pmat{*}{*}{0}{*}$, and by $T$ the span of all matrices of the form $\pmat{x}{\varepsilon y}{y}{x}$

Let $U$ denote the matrices of the form $\pmat{1}{*}{0}{1}$. Then $B/U \cong (\F_q^\times)^2$ (picks out two diagonal entries of $B$). 

Given $\alpha,\beta:\F_q^\times\to\C^\times$ reps of $\F_q^\times,$, then we have a rep $\psi_{\alpha,\beta}:B\to B/U \simeq(\F_q^\times)^2 \to \C^\times$, where this second morphism is by $\alpha\boxtimes\beta$. \begin{center}
\begin{tabular}{c| c c c c}
\, &$z_x$ & $d_{x, y}$ & $u_x$ & $t_{x,y}$ \\
\hline
triv & 1 & 1 & 1 & 1 \\
std & $q$ & 1 & 0 & -1 \\
$\Ind_B^{\GL_2(\F_q)}\psi_{\alpha,\beta}$ & $(q+1)\alpha(x)\beta(x)$ & $\alpha(x)\beta(y) + \alpha(y)\beta(x)$ & $\alpha(x)\beta(x)$ & 0 \\
\end{tabular}
\end{center}
This third line is irreducible if $\alpha \neq \beta$. Note $\Ind_B^{\GL_2}\psi_{\alpha,\beta} = \Ind_B^{\GL_2}\psi_{\beta,\alpha}$
$\Ind_B^{\GL_2}\psi_{\alpha,\alpha} = \alpha\circ\det\oplus(\alpha\circ\det)\otimes(\alpha) (?)$

Recall we proved last time that if $G$ is a finite group, $R(G)$ the representation ring. As a group, $R(G)$ is generated by the irreps of $G$. Multiplication is given by expressing the tensor of two irreps as a sum of two irreps. Given $V \in R(G)$, $V$ is the class of an irrep if and only if $\langle \chi_V, \chi_V \rangle =1$, and $\chi_V(\Id_G) > 0$. 

Now, we can think of $T$ as being isomorphic to $\{x + \sqrt{\varepsilon}y \in \F_{q^2}^\times\}$. Given a $\varphi:\F_{q^2}^\times\to\C^\times$, we have
\begin{center}
\begin{tabular}{c| c c c c}
\, &$z_x$ & $d_{x, y}$ & $u_x$ & $t_{x,y}$ \\
\hline
triv & 1 & 1 & 1 & 1 \\
std & $q$ & 1 & 0 & -1 \\
$\Ind_B^{\GL_2(\F_q)}\psi_{\alpha,\beta}$ & $(q+1)\alpha(x)\beta(x)$ & $\alpha(x)\beta(y) + \alpha(y)\beta(x)$ & $\alpha(x)\beta(x)$ & 0 \\
$\Ind_T^{\GL_2(\F_q)}\varphi$ & $q(q-1)\varphi(x)$ & 0 & 0 & $\varphi(\zeta) + \varphi(\zeta)^q(?)$
\end{tabular}
\end{center}
where $\zeta = x + \sqrt{2}y$(?). There's another very convoluted row I didn't quite catch you get by putting the others together in various ways, but that's all of them. 

For more: wikipedia Deliegne-Lustztig(sp?) theory.

The story of $\SL_2(\F_q)$ is similar: restrict reps fo $\SL_2(\F_q)$, some of the $\alpha,\beta$ break up (into at most two pieces), there's some redundancies, and every rep of $\SL_2(\F_q)$ is a restriction. 

Fun exercise: Show $\PSL_2(\F_q)$ is simple for $q > 3$ odd.

\section*{\underline{Lie Algebras}}

Let $k$ be an arbitrary field, $\g$ a finite dimensional $k$-vector space. 

\defn

A \underline{Lie bracket} $[-,-]:\g\times\g\to\g$  
\begin{itemize}

\item is Bilinear, meaning $[-,*]:\g\to\g$ is linear, as is $[*,-]$ for any $*\in\g$

\item is Alternating, meaning $[x,x] = 0$ for all $x \in \g$. This implies $[x,y]=-[y,x]$. In characteristic 2, this is \underline{stronger}!

\item satisfies the \underline{Jacobi Identity:}
\[
[x,[y,z]] + [y,[z,x]] + [z, [x, y]] = 0
\]

\end{itemize}

A \underline{Lie Algebra} is a finite dimensional $k$-vector space $\g$ with a Lie bracket. 

\cor

$[x,y] = -[y,x]$

\proof

$[x + y, x + y] = [x, x] + [y, y] + [x,y] + [y,x] = 0$

\qed

\exm
\,
\begin{itemize}

\item Let $R$ be an associative $k$-algebra. Then $[x, y] = xy - yx$ will be a Lie bracket. 

\item $\Mat_{n\times n}(k)$ is a Lie algebra with 
\[
[A,B] = AB - BA
\]

\item We have $\mathfrak{s}l_n(k) \subseteq \Mat_{n\times n}(k)$ the set of all matrices with trace 0. Then $[A,B] = AB - BA$ is again a Lie bracket. 

\item A Lie algebra is \underline{abelian} if $[-,-] = 0$ for all vectors.

\end{itemize}

Suppose $R$ is a commutative $k$-algebra. A \underline{$k$-derivation} $\delta:R\to R$ is a $k$-linear map such that $\delta(a) = 0$ for $a \in k$, and $\delta(xy) = \delta(x)y + x\delta(y)$. 

\exm
\,

We can take $R = k[t], \delta = \pp{}{t}$.

\underline{Fact:}

$Der_k(R)$, the set of all $k$-derivations on $R$, is a Lie algebra, with $[\delta,\gamma] = \delta\circ\gamma - \gamma\circ\delta$.

\section*{Lecture 12, 13/2/25}

Let's prove the above fact. 

\claim $Der_k(R)$ is a Lie algebra, with bracket $[\delta,\gamma] =\delta\circ\gamma - \gamma\circ\delta$.

\proof

We have
\begin{align*}
\delta\circ\gamma(xy) & = \delta(\gamma(x)y + x\gamma(y)) \\
& = \delta\gamma(x)y + \gamma(x)\delta(y) + \delta(x)\gamma(y) + x\delta\gamma(y) \\
\gamma\circ\delta(xy) & = \cdots \\
(\delta\circ\gamma-\gamma\circ\delta)(xy) & = \delta\gamma(x)y + x\delta\gamma(y) - \gamma\delta(x)y - x\gamma\delta(y)
\end{align*}
\qed

\exm
\,
\begin{itemize}

\item If $M$ is a smooth manifold, $Der_\R(C^\oo(M)) = C^\oo$ vector fields on $M$. 

\item If $G$ is a Lie group (i.e. a $C^\oo$ manifold equipped with a $C^\oo$ group structure). Define $Lie(G)$ to be the space of left $G$-invariant vector fields. This has another description as the tangent space of the identity, $T_eG$.
\end{itemize}

\defn

Let $\g$ be a Lie algebra over $k$. A \underline{representation of $\g$} is a $k$-linear map $\rho:\g\to\Mat_{n\times n}(k)$ which respects the Lie bracket, i.e. $\rho([x,y]) = [\rho(x),\rho(y)]$, where on the right hand side it's just the commutator of matrices. 

\defn

Given Lie algebras $\g, \h$ over a field $k$, a \underline{homomorphism} $f:\g\to\h$ is a $k$-linear map such that $f([x,y]) = [f(x),f(y)]$ for all $x, y \in \g$. 

Equivalently, a representation is a Lie algebra morphism $\rho:\g\to\gl_n$. Equivalently, $\gl(V) = \End(V)$, so a rep is a morphism $\g\to\gl(V)$

\defn

The \underline{Universal Enveloping Algebra} $U\g$ is defined by 
\[
U\g \eqdef \frac{\bigoplus_{n\geq0}\g^{\otimes n}}{\langle x\otimes y -  y\otimes x - [x,y] \forall x, y \in \g \rangle}
\]

Main property:
\[
\Hom_{\text{Assoc }k-\text{ alg }}(U\g,R) = \Hom_{Lie}(\g,R)
\]

\defn

A (finite-dimensional) $\g$-representation is the same as a left $U\g$-module which is finite dimensional as a $k$-vector space.

\exm
\,
If $\g$ is the Lie algebra of a Lie group, then $U\g$ is the left-invariant differential operators. 

\exm
of representations
\,
\begin{itemize}

\item $\Id:\g = \gl_n\to\gl_n$. Inside of $\gl_n$ is $\mathfrak{s}l_n$, and this gives a rep of it. 

\item $k, [-,-] = 0$ is repped by sending $*$ to $\pmat{0}{*}{0}{0}$. The span of $\begin{pmatrix}1\\0\end{pmatrix}$ is a subrepresentation.

\item $\rho_A:k\to\gl_n, * \mapsto *A$

\end{itemize}

\defn

Let $\rho:\g\to\gl(V)$ be a representation. $W \subseteq V$ is a \underline{subrepresentation} if for all $x \in \g, w \in W, \rho(x)w \in W$. This is the same as saying $W$ is a $U\g$-submodule of $V$. 

\exm

Let $\mk{b}_n$ be the Lie algebra of upper triangular matrices. It contains $\mk{N}_n$, the strictly upper triangular matrices. The former is solvable, the latter nilpotent. 

Given some representations, how can we make new ones? 

\subsection*{\underline{Operations on representations}}

Let $\g$ be a Lie algebra over $k$, $V, W$ representations of $\g$, i.e. are equipped with $\rho_V:\g\to\gl(V),\rho_W:\g\to\gl(W)$.

\begin{itemize}

\item $\rho_V\oplus\rho_W:\g\to\gl(V)\oplus\gl(W) \to \gl(V\oplus W)$ via the block matrix $\pmat{\rho_V(x)}{0}{0}{\rho_W(x)}$

\item $V^*$ is a rep via $\rho_{V^*}:\g\to\gl(V^*)$ sending $x \mapsto (f \mapsto f(-\rho_V(x)))$

\item $\rho_{V\otimes W}:\g\to\gl(V\otimes W)$, $x \mapsto (v\otimes w \mapsto \rho_V(x)v\otimes w - v\otimes\rho_W(x)w)$

\item $\underline{\Hom}_k(V,W)$ via $x\cdot f = x\cdot f(-) - f(x\cdot -)$

\item $V^\g = \{v\in V \mid xv = 0 \forall x \in \g\}$

Observation: $\underline{\Hom}_k(V,W)^\g = \Hom_\g(V,W)$
\end{itemize}

\defn

A \underline{homomorphism of representations} is a $k$-linear $f:V\to W$ such that $f(x\cdot v) = x\cdot f(v)$ for all $x \in \g$, $v \in V$. 

\subsection*{\underline{Representations of $\sl_2(k)$}}

Let $k$ be a field of characteristic 0. $\sl_2\subseteq\Mat_{2\times2}(k)$ is the set of $2\times2$ matrices of trace 0. This is $\Span(\underbrace{\pmat{0}{1}{0}{0}}_{e},\underbrace{\pmat{0}{0}{1}{0}}_{f},\underbrace{\pmat{1}{0}{0}{-1})}_{h}$

Now, 
\[
[e,f] = \pmat{0}{1}{0}{0}\pmat{0}{0}{1}{0} - \pmat{0}{0}{1}{0}\pmat{0}{1}{0}{0} = \pmat{1}{0}{0}{1} = -h
\]
Similarly, 
\[
[h,f] = \pmat{1}{0}{0}{-1}\pmat{0}{0}{1}{0}-\pmat{0}{0}{1}{0}\pmat{0}{0}{0}{-1} = \pmat{0}{0}{-2}{0} = -2f
\]
\[
[h,e] = \pmat{1}{0}{0}{-1}\pmat{-1}{1}{0}{0}-\pmat{0}{1}{0}{0}\pmat{1}{0}{0}{-1} = \pmat{0}{2}{0}{0} = 2e
\]

A representation of $\sl_2$ on $V$ is $E, F, H \in \gl(V)$ such that
\begin{align*}
[E,F] & = H \\
[H,F] & = -2F \\
[H,E] & = 2E
\end{align*}

Given these, we can consider $\sl_2\to\gl(V)$ by $e \mapsto E, f \mapsto F, h \mapsto H$.

\lem

$E, F$ are nilpotent, i.e. some power of them are 0. 

\proof

WLOG, $k = \bark$. Otherwise, we could just lift to the algebraic closure, and check it is nilpotent there, and then it will be nilpotent over $k$. 

Let $v$ be an eigenvector of $H$ with eigenvalue $\lambda$. 
$HFv = - 2Fv + FHv = -2Fv + \lambda Fv = (\lambda-2)Fv$. Similarly, $HEv = (\lambda+2)Ev$. So $F^nv = E^nv = 0$ for $n$ sufficiently large, because otherwise $H$ would have infinitely many distinct eigenvalues. 

Now let $W \subseteq V$ be the span of eigenvectors of $H$. This is a subrepresentation of $\sl_2$ (because $F$ and $E$ send eigenvectors to eigenvectors as shown above). Now consider $V/W$. This is again an $\sl_2$-representation, so by induction on dimension $E, F$ act nilpotently on it. 

\qed

Here is another proof:

\proof

Let's compute 
\begin{align*}
\tr(E^n) & = \tr(\frac{1}{2}E^{n-1}[H,E])\\
& = \frac12\tr(E^{n-1}HE - E^nH)\\
& = 0
\end{align*}

Let $\lambda_1,\dots,\lambda_n$ be the generalized eigenvalues of $E$ with multiplicity. Then $0 = \tr(E^n) = \sum \lambda_i^n$.

Why? In characteristic 0, these generate all symmetric polynomials in $\lambda_i$. 

The characteristic polynomial of $E$ is $x^n - \sum(\lambda_i)x^{n-1} + \sum_{i< j}\lambda_i\lambda_j)x^{n-2} + \cdots + = x^n$. So the characteristic polynomial is $x^n$, so it's nilpotent by Cayley-Hamilton.

\qed

For now, we will use $k = \C$ so we can say things like ``maximal real part." 

\lem

Let $\lambda$ be the eigenvalue of $H$ with maximal real part. Let $v$ be an $H$-eigenvector with eigenvalue $\lambda$. Let $n$ be minimal such that $F^nv = 0$ (there is such an $n$ because $F$ is nilpotent). Then $Ev = 0, \Span(v, Fv, \dots, F^{n-1}v)$ is a subrepresentation of $V$, $\lambda = n - 1$. In particular, the eigenvalues of $H$ are all integers. 

\proof

\begin{align*}
EFv & = EFv - FEv \\
& = Hv \\
& = \lambda v\\
EF^2v & = [E,F]Fv + FEFv \\
& = HFv + \lambda Fv \\
& = (\lambda-2)Fv + \lambda Fv \\
& = (2\lambda-2)Fv \\
\cdots & \\
EF^nv & = (\lambda^2 + (\lambda + 1)n))F^{n-1}v 
\end{align*}
So this is a subrep. 
\begin{align*}
0 & = EF^Nv \\
& = (-N^2 + (\lambda-1)NF^{N-1}V
\end{align*}
So $(\lambda+1)N - N^2 = 0$. So either $N = 0$ (which isn't the case), or $\lambda = N - 1$. 

\underline{Explicit:}

Set $v = v_0, v_i = F^iv_0$, so $Fv_i = v_{i+1}$. $Hv_n = (N - 2 - 2n)v_n$, $Ev_n = (-n^2 + Nn)v_{n-1}$.

Let's call this representation $V_N$.

\cor

For any non-zero representation $W$ of $\sl_2$, there exists an $N > 0$ such that $V_N$ is a subrepresentation of $W$. 

\proof

\qed

$V_1 \leq \sl_2 \to \gl_2$. 

$V_n = Sym^N(V_1)$, where $x \in \sl_2$ acts on $v_1\otimes v_2\otimes\cdots\otimes v_N$ by 
\[
x\cdot(v_1\otimes\cdots\otimes v_N) = \sum_{i=1}^Nv_1\otimes\cdots \otimes xv_i\otimes\cdots\otimes v_N
\]

$V_N$ is the space of homogeneous polynomials in $X, Y$ of degree $N$.

$E$ acts by $X\pp{}{y}$, $F$ acts by $Y\pp{}{x}$, $H$ by $X\pp{}{x} - Y\pp{}{y}$.

\claim

$V_N$ are all irreps of $\sl_2$ (where irrep means the same as in the world of groups, i.e. no nontrivial subrepresentations). 

\proof

Any rep of $\sl_2$ contains one of these, so it suffices to show that they are irreducibe. 

Let $v = \sum a_iv_i \in V_N$ be any element. It suffices to show $\{F^av, E^bv, a, b \in \N\}$ span. Acting by some power of $E$, $E^av \in \Span(v_0)$.

But $V_n$ is the span of $F^av_0$, so we have shown its irreducible. 

\qed

\defn

$V$ a representation of $\g$ is \underline{semi-simple} if it's the direct sum of irreducibles. 

\thm

All finite dimensional representations of $\sl_2$ in characteristic 0 are semisimple. 

\proof

\qed

\section*{Lecture 13, 25/2/25}

\underline{Combinatorics question:}

Let $g_{n,k}$ be the number of unlabeled graphs with $n$ vertices and $k$ edges. 

Here are the $g_{n,k}$ for various $n$ 
\begin{enumerate}

\item 1

\item 1, 1

\item 1, 1, 1, 1

\item 1, 1, 2, 3, 2, 1, 1 

\item 1, 1, 2, 4, 6, 6, 6, 4, 2, 1

\item 1, 1, 2, 5, 9, 15, 21, 24, 24, 21,15, 9, 5, 2, 1, 1

\end{enumerate}

Observation: $g_{n,k} = g_{n, {n\choose 2}-k}$

\prop

The sequence $g_{n,k}$, for a fixed $n$, is unimodal in $k$, meaning these sequences are increasing until they peak in the middle, and then go down. 

\proof

We are going to use the representation theory of $\sl_2$ to prove this unimodality. 

Recall: $\sl_2 = \langle e,f,h\mid[e,f]=h,[h,f]=-2f,[h,e]=2e\rangle$

We have the standard 2-dimensional representation of $\sl_2, V$, given by the inclusion $\sl_2\into\gl_2$

Last time, we showed all irreps of $\sl_2$ are isomorphic to $Sym^nV$ for some nonnegative integer $n$, where $x \in \sl_2$ acts on $v_1\otimes\cdots\otimes v_n$ as 
\[
(x\cdot v_1)\otimes v_2\otimes\cdots\otimes v_n + v_1\otimes(x\cdot v_2)\otimes\cdots\otimes v_n + \cdots + v_1\otimes\cdots\otimes (x\cdot v_n)
\]

We have $h \in \sl_2$ given by $\pmat{1}{0}{0}{-1}$. Fix $v_1, v_{-1} \in V$ such that $hv_1 = v_1, hv_{-1} = -v_{-1}$. Then $h$ acts by 
\[
h\cdot(v_1^av_{-1}^b) = (a + b)v_1 + v_{-1}^b
\]
So $h$ acts on $Sym^nV$ with eigenvalues $n, n-2, \cdots, -n + 2, -n$

Lemma:

Let $V$ be any finite dimensional $\sl_2$-representation (not necessarily irreducible). 

\lem

Let $d_r$ be the dimension of the generalized eigenspace of $h$ with generalized eigenvalue $r$. 

Then $\{d_r\}_{r\text{ even }},\{d_r\}_{r\text{ odd }}$ are both unimodal and in particular $d_r = d_{-r}$

\proof

By induction on $\dim V$. The base case will be $\dim V = 0$, where it easily holds. 

Now, assume the claim holds for $\dim V < n$. Suppose $\dim V = n$. Let $W \subseteq V$ be irreducible. By induction, the claim is true for $V/W$. By the classification of irreps, it's true for $W$. But these properties are preserved by addition. 

\qed

The goal now is to write down some generalized eigenspaces of $h$ with exactly this sequence as it's $d_r$'s. 

Let $V_n$ be the vector space consisting of formal linear combinations of labeled graphs with $n$ vertices. 

Observation: $S_n\curvearrowright V_n$ by permuting the vertices. 

Let $V_{n,k}$ be the span of the graphs with $k$ edges. Then 
\[
V_n = \bigoplus_{k=0}^{n\choose 2} V_{n,k}
\]

Observe that $g_{n,k} = \dim V_{n,k}$

Given $i < j \in \{1,\dots,n\}$, for a labeled graph $g$, set $a_{ij}(g) = \begin{cases} g \cup (i,j) & \text(i,j)\text{ not an edge } \\ 0 & \text{ otherwise } \\ \end{cases}$. Similarly, set $b_{ij}(g) = \begin{cases} g\setminus(i,j)&(i,j)\text{ an edge }\\ 0 & \text{ otherwise } \\ \end{cases}$.

Let $E = \sum_{i<j}a_{ij}, F = \sum_{i<j}b_{ij}, H = [E, F]$. 

$[a_{i,j},a_{k,\ell}] = 0$, $[b_{i,j},b_{k,\ell}] = 0$, and $[a_{i,j},b_{k,\ell}] = 0$ if $(i,j)\neq(k,\ell)$, $g$ if $(i,j) = (k,\ell)$ and $g$ an edge, $-g$ otherwise. 

Now
\begin{align*}
Hg & = [E,F]g \\
& = \sum_{(i,j) \in g}g - \sum_{(i,j) \not\in g}g \\
& = ((2(\text{number of edges of g} - {n\choose 2})g \\
\end{align*}

Doing this with $[H,F]g$, it turns out this is $-2Fg$. 

Next $\sl_2\curvearrowright V_n^{S_n}$, and $h$ has eigenspaces $V_{n,k}^{S_n}$ with eigenvalues $2k - {n\choose2}$ and hence $g_{n,k} = \dim V_{n,k}^{S_n}$ is unimodal. 


\section*{Lecture 14, 4/3/25}

Let $k = \bark$ be an algebraically closed field (of any characteristic for now), and $\g$ a Lie algebra over $k$. 

\exm
\,
Recall: Given Lie algebra reps $V, W$, 
\begin{itemize}

\item $V\oplus W$ given by $x\cdot(v,w) = (x\cdot v, x\cdot w)$

\item $V\otimes W$ given by $x\cdot(v\otimes w) = (x\cdot v)\otimes w + v\otimes(x\cdot w)$

\item $V^*$, given by $(x\cdot f)(v) = f(-x\cdot v )$

\item $V^\g = \{v\in V \mid xv = 0 \forall x \in \g\}$

\end{itemize}

Exercise: $\underline{\Hom}_k(V,W)^\g = \Hom_\g(V,W)$

We have $\sl(V) \into \gl(V)$ is a representation, so $\sl(V) \curvearrowright V\otimes V = Sym^2V \oplus \bigwedge^2 (V)$ for $char \neq 2$

Pick $q \in Sym^2V$, $\omega \in \bigwedge^2CV$, both non-degenerate. 

Then $\so(q) = \{x\in \sl(V) \mid xq = 0\}$, $\sp(\omega) = \{x\in\gl(V) \mid x \cdot \omega = 0\}$

Goal: Study Lie algebras with nice representation theory.

Basic examples will be $\sl,\so,\sp$, and a finite list of exceptional algebras. 

Structure: 

There are 2 basic classes of Lie algebras:
 
\begin{itemize}

\item Solvable

\item Semisimple

\end{itemize}

Every finite dimensional Lie algebra is built out of these two types. 

\defn

A subspace $I\subseteq\g$ is an \underline{ideal} if for all $x \in I, v \in \g, [x,v] \in I$. 

Then $\g/I$ naturally inherits the structure of a Lie algebra. 

\lem

Let $I_1, I_2 \subseteq \g$ be ideals. Then 
\begin{itemize}

\item $I_1 + I_2$ is an ideal

\item $I_2 \cap I_2$ is an ideal 

\item $[I_1,I_2] = \langle[x,y] \mid x \in I_1, y \in I_2\rangle$ is an ideal 
\end{itemize}

\proof

Exercise

\qed

\exm
\,
\begin{itemize}

\item $[\g,\g]$ is an ideal (the commutator). 

\item $[\gl(V),\gl(V)] = \sl(V)$. 

\item $\g/[\g,\g]$ is abelian. 

\end{itemize}

\defn
\,
\begin{itemize}

\item $D^0\g = [\g,\g], D^i\g = [D^{i-1}\g,D^{i-1}\g]$. This is the \underline{derived series}, or \underline{central series}

\item $C^0\g = \g, C^i\g = [\g, C^{i-1}\g]$ This is the \underline{lower central series}

\end{itemize}

\defn

$\g$ is \underline{solvable} if $D^i\g = 0$ for some $i$, and \underline{nilpotent} if $C^i\g = 0$ for some $i$. 

Solvability means if we take $[[[x_1,x_2],[x_3,x_4]],[\cdots] = 0$ if there are enough of them.

Nilpotency essentially means that $[x_1,[x_2,[x_3,\cdots,]]]] = 0$ once you have enough of them.

Unlike in the case of groups, these two notions are extremely closely related. 

\exm

$\mk{b}_n = \{\begin{pmatrix} * & \cdots & * \\ \vdots & \ddots & \vdots \\ 0 & \cdots & * \\ \end{pmatrix}\}$, the upper triangular matrices.

$\mk{n}_n = \{\begin{pmatrix} 0 & \cdots & * \\ \vdots & \ddots & \vdots \\0 & \cdots & 0 \\ \end{pmatrix}\}$, the nilpotent matrices (strictly upper triangular). 

Exercise: $[\mk{b}_n,\mk{n}_n] = \mk{n}_n$

\prop

$\mk{n}_n$ is nilpotent. 

\proof

We claim $C^i\mk{n}_n$ is the set of upper triangular matrices with the first $i$ superdiagonals are zero. This is because the product of two things of this form has the first $i + 1$ superdiagonals zero. 

\defn

The \underline{radical} of $\g$ is the maximal solvable ideal in $\g$. 

This is a valid thing to write because there is a unique such ideal, but we must show this: 

\lem

Let $I_1, I_2 \subseteq \g$ be solvable ideals. Then $I_1 + I_2$ is solvable. 

\proof

$(I_1 + I_2)/I_1 = I_2/(I_1\cap I_2)$. These ideals and $I_1$ are solvable. 

\claim

If $\g$ is a Lie algebra, and $I \subseteq \g$, $\g/I$ are both solvable, then $\g$ is solvable. 

\proof

$D^i(\g/I) = 0$ for some $i$. This implies $D^i\g \subseteq I$. But iterated commutators are zero in $I$ by assumption. 

\qed

\qed

\cor

There exists a unique maximal solvable ideal in $\g$, denoted $\rad(\g)$

\proof

We can take the span of all solvable ideals. 

\qed

\defn

$\g$ is \underline{semisimple} if $\rad(\g) = 0$

\prop

For any $\g$, $\g/\rad(\g)$ is always semisimple. 

\proof

$I\subseteq \g/\rad(\g)$ is a solvable ideal if its preimage under the quotient map is solvable, and this would be an extension of $\rad(\g)$. 

\exm
\,
\begin{itemize}

\item $\sl_n$ is simple, meaning there are no non-zero proper ideals

\item $\so(q)$ is simple as well

\item $\sp(\omega)$ is as well

\end{itemize}

Non-example:

$\gl(V)$ is NOT semisimple, since scalar matrices make up a solvable ideal.

\defn(For culture)

$\g$ is \underline{reductive} if $\rad(\g) = \mk{z}(\g) = \{x \in \g\mid [x,v] = 0 \forall v \in \g\}$

\section*{Lecture 15, 6/3/25}

Recall we were studying the class of nilpotent Lie algebras, which are a subclass of the class of solvable lie algebras.

Recall a lie algebra is semisimple if $\rad(\g) = 0$, that is there are no nonzero solvable ideals. 

Standard examples of solvable Lie algebras include $\mk{b}_n$, the $n\times n$ upper triangular matrices, and standard example of a nilpotent Lie algebra is $\mk{n}_n$, the strictly upper triangular matrices. 

Standard example of semisimple Lie algebra is $\sl_n$. 

\thm(Sophus Lie)

Suppose $\g$ is solvable. Then any representation of $\g$ is upper triangularizable, i.e. given a representation $\rho:\g\into\gl(V)$, there exists a basis of $V$ in which $\rho(x)$ is upper triangular for all $x\in\g$, i.e. $\rho$ can be conjugated (by $\GL(V)$) into $\mk{b}$, i.e. there exists a full flag $V_1 \subsetneq V_2 \subsetneq \cdots \subsetneq V_n$, with $\dim V_i = i$, where each $V_i$ is a representation. 

\proof

\lem

Suppose $\g$ is solvable, $\rho:\g\to\gl(V)$ a representation. Then there exists some $v \in V$ so that $v$ is an eigenvector for $\rho(x)$ all $x \in \g$.

\proof

We will prove this by induction on dimension. It is clearly true for $\dim \g = 0$, so this is our base case. 

Now for the induction step: $[\g,\g]\subsetneq\g$ because $\g$ is solvable. 

Pick $\g'\subseteq\g$ so that 
\,
\begin{enumerate}

\item $[\g,\g]\subseteq\g'$

\item $\codim(\g') = 1$

\end{enumerate}

Now observe 
\begin{enumerate}[label=(\alph*)]

\item $\g'$ is an ideal because for all $x \in \g', y \in \g$, $[x, y] \in [\g,\g]\subseteq\g'$. 

\item $\g'$ is solvable.

\end{enumerate}

Pick $x \in \g\setminus\g'$. 

By the induction hypothesis, there exists some $w \in V$ such that $y\cdot w = \lambda(w)$ for all $y \in \g'$. 

Let $W = \Span(w, x\cdot w, x^2\cdot w, \cdots)$

\claim

For all $y \in \g'$, $yx^kw = \lambda(y)x^kw + \sum_{\ell<k}a_{\ell k}(y)x^\ell w$, $k < \dim W - 1$ i.e. $y \in \g'$ acts on $W$ via an upper triangular matrix with $\lambda(y)$ on the diagonal. 

\proof

We prove this by induction on $k$. For $k = 0$ it is certainly true, so this is our base case.

For the induction step: 
\begin{align*}
yx^kw & = xyx^{k-1}w + [y,x]x^{k-1}w \\
& = \lambda(y)x^kw + \text{ lower order terms } + \lambda([y,x])x^{k-1}w + \text{ lower order terms }
\end{align*}

So $\tr(y|W) = \dim W \cdot \lambda(y)$ for all $y \in \g'$

This implies that $\lambda([y_1,y_2]) = 0$ (here we use the assumption $k = \bark$) for all $y_1,y_2\in\g$.

The lower order terms are all ultimately built out of commutators, so $\g'$ acts on $W$ via $\lambda-\Id$. 

Now choose $v \in W$ an $x$-eigenvector. 

This proves the claim. 

\qed

Let's prove the theorem via a full flag. 

Given a rep $\g\into\gl(V)$, we can now pick an eigenvector $v \in V$. Now consider the action of $\g$ on $V/V_1$, where $V_1 = \Span(v)$. But $\dim(V/V_1) < dim(V)$, so by induction we win. 

\qed

\cor

Any irrep of a solvable Lie algebra is 1-dimensional. 

\proof

For any $\g\into\gl(V)$, there exists a common eigenvector, which means every rep has a 1-dimensional sub representation. 

\qed

\cor

$\g$ is solvable if and only if $[\g,\g]$ is nilpotent. 

\proof

We start with the easy direction: it is enough for $[\g,\g]$ to be solvable. Because then $[\g,\g]$ and $\g/[\g,\g]$ are solvable, so their product, $\g$, is solvable. 

Now for the other direction. 

\defn

Let $\g$ be a Lie algebra. The \underline{adjoint representation} is the map $\ad:\g\to\gl(\g)$, given by $x\mapsto[x,-]$.

Observe $\ker\ad = \mk{z}(\g)$, the center. 

Suppose $\g$ is solvable. By classification of representations, the adjoint representation factors through $\mk{b}$:
\[
\begin{tikzcd}
\g\ar[dr] \ar[rr, "\ad"] & & \gl(\g) \\
& \mk{b} \ar[ur] & \\
\end{tikzcd}
\]
Observe
\begin{enumerate}[label=(\roman*)]

\item $[\mk{b},\mk{b}] \subset \mk{n}$, and $\mk{n}$ is nilpotent

\item $[\g/\mk{z}(\g), \g/\mk{z}(\g)]$ is nilpotent

\item $[\g,\g]$ is nilpotent by definition of center. 

\end{enumerate}

\qed

Recall $\g$ is semisimple if $\rad(\g)=0$.

\exm

Let $\g = \sl_2$. We have $\ad:\sl_2\to\gl(\sl_2)$.

$h = \pmat{1}{0}{0}{-1}\to[h,-]$

Eigenvalues of $0, 2, -2$, with eigenvectors $h, ev_f$, and $fwe$ (?), respectively.

Suppose $I \subseteq \sl_2$ is an ideal. Then $\ad(h)$ preserves $I$. 

So this means that none of the possible subalgebras are ideals (can check each of them 1 by 1 because there are only finitely many). 

So in particular there are no nontrivial solvable ideals. 

\cor

$\sl_2$ is simple (meaning no nontrivial ideals). 

\thm

Let $V$ be an irrep of a Lie algebra $\g$. 

Then for all $x \in \rad(\g)$, $x$ acts on $V$ via scalars. For all $x \in [\rad(\g),\g]$, $x$ acts on $V$ by 0

\proof(sketch)

Let $v \in V$ be an eigenvector for $\rad(\g)$, i.e. for all $x \in \rad(\g)$, $x\cdot v = \lambda(x)\cdot v$

Let $V_\lambda = \{w\in V \mid x\cdot w = \lambda(x)\cdot w\forall x \in \rad(\g)\}$

Fix $y \in \g, x \in \rad(\g)$. Let $w \in V_\lambda$. Then $xyw = yxw + [x,y]w = \lambda(x)yw + \lambda([x,y])w$

We can set $W = \Span(w,y\cdot w, y^2\cdot w, \cdots)$. This is certainly preserved by $y$, and to show it's preserved by the radical you do something similar as the previous theorem.

\qed

Look at theorem 6.16 in the book for this course (Kiralov (sp?))

\subsection*{\underline{Bilinear forms}}

\defn

Let $\g$ be a Lie algebra. A bilinear form $B$ on $\g$ is \underline{invariant} if 
\[
B([x,y],z) + B(y,[x,z]) = 0
\]
for all $x, y, z \in \g$.

\prop

Suppose $\g$ is a Lie algebra, $B$ an invariant bilinear form on $\g$, $I \subseteq \g$ an ideal. 

Then $I^\perp = \{x \mid B(x,y) = 0 \forall y \in I\}$ is an ideal. 

\proof

Let $x \in I, y \in \g, z \in I^\perp$. We want to show $[y,z] \in I^\perp$.

We have $B([y,z],x) = -B(z,\underbrace{[y,x]}_{\in I}) = 0$

\qed

\cor

Let $\g, B$ as before. Then $\g^\perp$ is an ideal. 

\qed

\exm

Take $\g = \gl_n$, $B(x,y) = \tr(xy)$. Then 
\begin{align*}
\tr([x,y],z) + \tr(y,[x,z]) & = \tr(xyz - yxz) + \tr(yxz - yzx) \\
& = 0
\end{align*}

\exm

Let $\rho:\g\to\gl(V)$ be a representation. Then we may define
\[
B_\rho(x,y) = \tr(\rho(x)\rho(y))
\]

How to check if $B$ is nondegenerate:

We have $B:V\times V \to k$

We have a $\psi_B:V \to V^*$ given by $x\mapsto B(x,-)$.

Then $B$ is non degenerate if $\psi_B$ is an isomorphism. So we can pick a basis $e_1,\dots,e_n$, and show $\det(B(e_i,e_j)) \neq 0$.

\thm

Suppose there exists $\rho$ with $B_\rho$ non-degenerate. Then $\g$ is reductive (i.e. $\rad(\g) = \mk{z}(\g)$).

\proof

It is enough to show $[\g,\rad(\g)] = 0$

But $\rho([\g,\rad(\g)])$ acts by zero on any irreducible representation of $\g$

\claim

This implies $[\g,\rad(\g)] \subseteq \ker B_\rho$

\proof

By induction on $\dim \rho$, $\rho$ irreducible (otherwise we take a irreducible subrep $\psi\subseteq\rho$). 

It is enough to show $B_\rho = B_\psi + B_{\rho/\psi}$

$B_\rho$ being nondegenerate means $\ker B_\rho = 0$, so $\rad(\g) = \mk{z}(\g)$ 

(?)

\qed

\cor

$\gl_n,\sl_n,\so(n),\sp(2n)$ are all reductive. 

\proof

We will do the proof for $\gl_n$. 

Take $\rho = \Id:\gl_n\to\gl_n$, $B_\rho(x,y) = \tr(xy)$.

Let $e_{ij}$ be the matrix with $(e_{ij})_{k\ell} = \delta_{k\ell}^{ij}$.

We see $B(e_{ij},e_{k\ell}) = \delta_{i\ell}\delta{jk}$

\qed

\section*{Lecture 16, 11/3/25}

\defn

Let $\g$ be a Lie algebra. 

The \underline{Killing form} $K$ is defined as $K = B_{ad}$, so $K(x,y) = \tr(\ad(x)\cdot\ad(y))$

\thm
\,
\begin{enumerate}[label=(\alph*)]

\item $\g$ is semisimple iff $K$ is non-degenerate

\item $\g$ is solvable if and only if $K([\g,\g],\g) = 0$.

\end{enumerate}

\proof

Next time.

\defn

Let $k = \bark, char k = 0$, $\g$ a finite dimensional $k$-Lie algebra. 

A bilinear form $B:\g\times\g\to k$ is \underline{invariant} if
\[
B([x,y],z) + B(y,[x,z]) = 0
\]

Given a representation $\rho:\g\to\gl(V)$, there is a canonical form 
\[
B_\rho(x,y) = \tr(\rho(x)\rho(y))
\]

\defn

The \underline{Killing form}  is given by $K = B_{\ad}$, so $K(x,y) = \tr(\ad(x)\ad(y))$

\thm[Cartan's criterion]
\,
\begin{enumerate}[label=(\alph*)]

\item $\g$ is semisimple if and only if $K$ is non-degenerate

\item $\g$ is solvable if and only if $K([\g,\g],\g) = 0$

\end{enumerate}

\cor

Let $\g$ be semisimple, $I \subseteq \g$ an ideal. 

Then there is an $I'\subseteq\g$ such that $\g = I\oplus I'$ (as a Lie algebra).

\proof

$\g$ is semisimple, so by the theorem (yet to be proven), we can take $I'$ to be the perpendicular subspace under $K$, and $\dim I + \dim I' = \dim \g$ simply because $K$ is non degenerate. 

We want to show $I \cap I' = 0$. 

\claim 

$K|_I$ is the killing form for $I$. 

\proof

Let $x, y \in I$. Then
\begin{align*}
K(x,y) & = \tr(\ad(x)\ad(y)|\g) \\
& = \tr(\ad(x)\ad(y)|I) + \underbrace{\tr(\ad(x)\ad(y)|\g/ I)}_{=0}
\end{align*}
because $\ad(x),\ad(y)$ act on $\g/I$ as 0. 

\qed

Now to prove the theorem. 

We wish to show $K|_I$ is non-degenerate. Let $x \in I$. We want to show there is a $y \in I$ with $K(x,y) \neq 0$. 

We know there is some $z \in \g$ such that $K(x,z) \neq 0$. 

He put it on the homework :(

\qed

\cor

If $\g$ is semisimple, then $\g$ is a direct sum of simple non-abelian Lie algebras. 

\proof

Given by induction on dimension: 

Choose any ideal $I \subseteq \g$. If it doesn't exist you're done. Otherwise $\g = I \oplus I'$. $I, I'$ are quotients of $\g$, hence semisimple, so we are done by the inductive hypothesis. 

\qed

\cor

If $\g$ is semisimple, then $[\g,\g] = \g$. 

\proof

It is enough to check for $\g$ simple and non-abelian (because $\g$ is a direct sum of such). 

But $[\g,\g] \subseteq \g$ is an ideal, hence everything, and $\g$ is nonabelian by assumption. 

\qed

\cor

Let $\g$ be semisimple. Then all finite dimensional $\g$-representations are semisimple (meaning a direct sum of irreps). 

\proof

\qed

Now to prove Cartan's criterion. 

For the rest of today, $k = \C$ (this is a convenience and it will turn out we can reduce to this case). 

\thm

Let $V$ be a finite dimensional vector space, $A \in \End(V)$. 
\begin{enumerate}

\item $A = A_s + A_n$, with $A_s$ diagonalizable and $A_n$ nilpotent, with $[A_n,A_s] = 0$. 

\item $\ad(A_s) = \ad(A)_s$. Moreover, $\ad(A)_s = P(\ad(A))$ for some polynomial with vanishing constant term $P \in C[t]$. 

\item Let $\bar{A_s}$ be the complex conjugate matrix. Then $\ad(\bar{A_s}) = Q(\ad A_s)$ for some polynomial $Q \in \C[t]$

\end{enumerate}

\proof[sketch]
\begin{enumerate}

\item First, write $A$ in Jordan normal form by choosing an appropriate basis. We can take $A_s$ to be the diagonal of this, and $A_n = A - A_s$. 

In basis free (and thus choice free (and thus canonical)) language, 

Let $V_\lambda = \ker((A-\lambda\Id)^N) N >>0$. $V = \bigoplus_\lambda V_\lambda$. We can take $A_s \eqdef (v_\lambda)_{\lambda\in\C} \to (\lambda v_\lambda)_{\lambda\in\C}$, and then $A_n = A - A_s$.

\item We want to show $A_s = P(A)$ for some $P \in \C[t]$. Let $n_\lambda = \dim V_\lambda$. Choose $p \in \C[t]$ such that 
\[
P \equiv \lambda \mod {t-\lambda)^{n\lambda}}\,\forall\lambda
\]
This exists by the chinese remainder theorem. 

Then $P(A) = \lambda$ on $V_\lambda$ because $(A - \lambda\Id)^{n_\lambda} = 0$ on $V_\lambda$

Remark: This tells us that $A_n$ is also a polynomial in $A$ ($A - P(A)$)

Now,
\begin{align*}
\ad(A) & = \ad(A_s + A_n) \\
& = \ad(A_s) + \ad(A_n)
\end{align*}

To see that $\ad(A_s) = \ad(A)_s$, it is enough to show $\ad(A_s)$ is diagonalizable, $\ad(A_n)$ is nilpotent (we can do this by computation), and $[\ad(A_s),\ad(A_n)] = 0$.

Computation for $\ad(A_s)$: 

$\ad(A_s)$ acts on $V_\lambda\otimes V_{\lambda'}^v$ as $\lambda - \lambda'$, 
\[
\End(V) = \bigoplus_{\lambda,\lambda'} V_\lambda\otimes V_{\lambda'}^v
\]

We know $P \in t\C[t]$ because $0$ is a generalized eigenvalue so $P \equiv 0 \mod t^{n_0}$

\item Choose $f$ so that $f(\lambda_i - \lambda_j) = \bar{\lambda_i} - \bar{\lambda_j}$ for all $i, j$ (Lagrange). Then $f(P(\ad(A)) = \ad\bar{A_s}$

\end{enumerate}

\section*{Lecture 17, 6/3/25}

We finish the proof. Let $\g$ be a Lie algebra over $\C$, and let $K(x,y) = \tr(\ad(x)\ad(y))$ be the Killing form.

\thm[Cartan]
\,
\begin{enumerate}[label=(\alph*)]

\item $\g$ is semisimple iff $K$ is non-degenerate

\item $\g$ is solvable iff $K(\g,[\g,\g]) = 0$.

\end{enumerate}

Last time we showed that if $I$ is an ideal (hence a sub-algebra), then the Killing form for $I$ is the Killing form for $\g$ restricted to $I$. 

\lem

Suppose $\g\subseteq\gl(V)$ is a Lie algebra such that for all $x \in \g$, $x$ is nilpotent. 

Then $\g$ is itself nilpotent. 

\proof[Sketch]

It is enough to show that there exists $v \in V$ such that $xv = 0$ for all $x \in \g$. 

By induction on $\dim V$: consider $V/\Span(v)$. Lift strict upper triangularizing basis to $V$, adjoin $v$ to it. 

To show that there exists such a $v$, use induction on $\dim \g$. 

For $\dim \g = 1$ note that nilpotent matrices have nonzero kernel. 

For the inductive step, let $\g' \subseteq \g$ be a maximal proper sub-algebra. 

Find $v$ with $\g'v = 0$, now copy the proof for solvable. 

\qed

\thm(Jordan)

Let $V$ be a finite dimensional $\C$-vector space, $A \in \End(V)$. Then
\begin{enumerate}

\item $A = A_s + A_n$ with $[A_s,A_n] = 0$, with $A_s$ diagonalizable and $A_n$ nilpotent.

\item $\ad(A)_s = \ad(A_s) = P(\ad(A))$,$P \in t\C[t]$ (i.e. $P$ has zero constant term). 

\item $\ad\bar{A_s} = Q(\ad A)$ for some $Q \in t\C[t]$

\end{enumerate}

\proof[Proof of Cartan]
\,
Most of the content in $(a)$ is proving $(b)$ so we'll prove $(b)$ first. 

We have $\ad:\g\to\mk{b}\subseteq \gl(\g)$, $[\g,\g]\to\mk{n} \subseteq \gl(\g)$, 
\[
K(x,y) = \tr(\underbrace{\ad(x)}_{\in\mk{b}}\underbrace{\ad(y)}_{\in\mk{n}}) = \tr(\text{strictly upper triangular matrix}) = 0
\]

To show that $K(\g,[\g,\g]) = 0\implies\g$ solvable, reduce to $\g \subseteq\gl(V)$. Then $\ad:\g\to\gl(V)$ has kernel $\mk{z}(\g)$

It is enough to show the image of the adjoint is solvable, because then $\g$ is an extension of a solvable by a solvable. 

Now, $\g \subseteq \gl(V)$, $K(\g,[\g,\g]) = 0$, and we want to show it's solvable. 

Pick $x \in [\g,\g], y \in \g$. Take $x = x_s + x_n$. To show $x$ is nilpotent, we want to show all its eigenvalues are zero. 

We will show $\tr(x_s\bar{x_s}) = \sum_{\lambda\in Spec(x_s)}|\lambda|^2$

By hypothesis we can write $x = \sum_i[y_i,z_i]$. 

\begin{align*}
\tr(x_s\bar{x_s}) & = \tr(\sum[y_i,z_i]\bar{x_s}) \\
& = \pm\sum\tr(y_i[z_i,\bar{x_s}]) \\
& = \pm\sum\tr(y_i\ad(x_s)z_i) \\
& = \pm \sum\tr(y_iQ(\ad(x)z_i))
\end{align*} 

But $y_i \in \g$, and $\ad(x)z_i \in [\g,\g]$ by definition, and $Q$ has no constant term, so this sum is 0. 

Finally, by assumption $K(\g,[\g,\g]) = 0$. 

So all eigenvalues are zero, so $x$ is nilpotent. 

By the lemma, $[\g,\g]$ is nilpotent, so $\g$ is solvable. 

We can reduce to the case of $\C$ by the ``Lefschetz principal". 

So now we prove part $(a)$. 

First, suppose that $K$ is nondegenerate. 

We already know $\g$ is reductive, i.e. $\rad(\g) = \mk{z}(\g)$. 

Let $x \in \mk{z}(\g)$. Then $K(x,y) = \tr(\ad(x)\ad(y)) = 0$, i.e. $x \in \ker K$. But $K$ is nondegenerate, so $x = 0$, so $\rad(\g) = 0$. 

Now suppose $\g$ is semisimple. 

Set $I = \ker K = \g^\perp$, which is an ideal. 

But by the earlier lemma, $K|_I \equiv 0$, so by part $(b)$, $I$ itself is solvable.

But $\g$ is semisimple, so $I = 0$. 

\qed

\cor[Corollaries on structure of semisimple Lie algebras]

\thm

Let $\g$ be semisimple, $I\subseteq\g$ an ideal. Then there exists an $I'$ with $\g = I \oplus I'$ as Lie algebras. 

\proof

Let $K$ be the killing form of $\g$. By Cartain, it is nondegenerate. Let $I' = I^\perp$. It is enough to show $I\cap I' = 0$.

$I \cap I'$ is an ideal such that $K|_{I\cap I'} = 0$. Now by Cartan, it is solvable, hence zero. 

\qed

\cor

Semisimple Lie algebras are direct sums of simple Lie algebras.

\cor

If $\g$ is semisimple then $[\g,\g]=\g$. 

\proof

We did these last time. 

\qed

\thm

Suppose $\g$ is semisimple. Then every representation of $\g$ is a direct sum of irreducible representations. 

In other words, any representation of a semisimple Lie algebras is semisimple. 

\proof

First Daniel wants to sketch a proof using the theory of Lie groups. 

\underline{Sketch:} 

\begin{enumerate}

\item Reduce to the case $k = \R$. 

\item $\g$ is the Lie algebra of a \underline{compact} Lie group $G$ such that

\item All representations of $\g$ come from representations of $G$, in the sense that the derivative of a Lie group representation is a Lie algebra representation. 

\item There exists a left-invariant Haar measure $\mu$ on $G$

\item It is now enough to show all reps of $G$ are semisimple

\item Given $G\to\GL(V)$, $W\subseteq V$ invariant, choose a projection $V\to W$, and take
\[
\frac{1}{\mu(G)}\int_G\rho(g,-)d\mu
\]
as in the proof of Maschke

\end{enumerate}

Here is a proof using stuff from this class: 

\underline{Idea:} Use the Laplacian on $G$. 

Recall: $Ug$ is the universal enveloping algebra of $\g$, defined by 
\[
Ug = \bigoplus_{i\geq0}\g^{\otimes i}/\langle x\otimes y - y\otimes x - px\rangle
\]
When $\g$ is the Lie algebra of a Lie group we can identify this with the left-invariant differential operators on $G$. 

\defn[Casimir operator]

Suppose $\g$ is a Lie algebra, $B$ an invariant nondegenerate bilinear form $B:\g\times\g\to k$. 

Choose a basis $(e_i)$ of $\g$, and let $(e^i)$ be the dual basis, i.e. 
\[
B(e_i,e^j) = \delta_{ij}
\]
Then $C_B = \sum e_ie^i \in Ug$. 

\prop

$C_B$ is central and independent of the choice of basis. 

\proof

We think of $B \in \g^*\otimes \g^*$. We can also think of it as $B \in \underline{\Hom}_k(\g,\g^*)^\g$. $B$ furnishes an isomorphism between $\g$ and $\g^*$. 

We would like an element of $\g\otimes\g$. 

We have an isomorphism $(\g^*\otimes\g^*) \to (\g\otimes\g)$ given by $B^{-1}\otimes B^{-1}$. 

The claim is that this sends $B$ to $C_B$. But $B$ was $\g$ invariant on the left, so it is $\g$-invariant on the right, and that's what it means to be central. 

\qed

\prop

Suppose $\g$ is semisimple, $\rho:\g\to\gl(V)$ is a nontrivial irreducible representation. 

Then there exists $C_\rho \in Z(Ug)$ such that $C_\rho$ acts on the trivial representation by $0$ and on $\rho$ by a nonzero scalar. 

\proof

Let $B_\rho(x,y) = \tr(\rho(x)\rho(y))$ 

Set $I = \ker B_\rho$. This is an ideal, so $\g = \g'\oplus I$ where $B_\rho|_{\g'}$ is invaraint and non-degenerate.

We have $C = C_{B_\rho|_{\g'}}\in Z(U\g') \into Ug$. 

\begin{enumerate}

\item $C$ acts trivially by 0: true for any element in $Ug_{>0}$

\item $C$ acts on $\rho$ by some scalar by Schur's lemma. We must check that this scalar is nonzero. 

\end{enumerate}

We have 
\begin{align*}
\tr(C|\rho) & = \tr(\sum e_ie^i|\rho) \\
& = \sum \tr(e_ie^i|\rho) \\
& = \sum B_\rho(e_i,e^i) \\
& = \sum 1 \\
& = \dim \g'\\
&\neq 0
\end{align*}
So in fact $\lambda = \frac{\dim \g'}{\dim V}$

\proof

\exm

Let $\g = \sl_2$, $B = K$. 

Take a basis $\sl_2 = \langle e, f, h \rangle$. We must compute a dual basis. 

We have $\ad(e): e \mapsto 0, f\mapsto h, h \mapsto -2e$

$\ad(f): e\mapsto -h, f \mapsto 0, h \mapsto 2f$

$\ad(h): e \mapsto 2e, f \mapsto -2f, h \mapsto 0$

We have $B(e,e) = 0, B(e, f) = 4, B(e,h) = 0$. So keep going, then we solve the system of equations 
\[
\begin{cases} B(e,ae + bf + ch) & = 1\\
B(f, \cdots) & = 0 \\
B(h,\cdots) & = 0 \\
\end{cases}
\]
We wind up getting $C = \frac12 h^2 + ef + fe$

\section*{Lecture 18, 18/3/25}

\thm

Let $\g$ be a semisimple (in the Lie algebra sense) Lie algebra over $\C$. Then any finite dimensional representation of $\g$ is itself semisimple (in the representation of a Lie algebra sense). 

\proof

\prop 

If $\g$ is a semisimple Lie algebra (always over $\C$), and $V$ is a non-trivial irreducible (always finite-dimensional) representation of $\g$, then there is a $C_V \in Z(U\g)$ such that $C_V$ acts on $V$ via a non-zero scalar and on the trivial representation by zero. 

\proof

Last time

\qed

\proof

Now let's prove the theorem. We will do this in three cases, each of which will reduce to the previous case. 

\paragraph{Case 1:} Let $W$ be a representation of $\g$, and suppose that all $C_V$ act on $W$ nilpotently. Then $W$ is trivial. 

\proof
\,

By induction on dimension of $W$: If $W$ is 1-dimensional then $W$ is trivial. 

Now suppose $\dim W > 1$. By assumption, $W$ is not irreducible. Let $U \subseteq W$ be a nontrivial proper subrepresentation. 

By induction, $U, W/U$ are trivial. But then the morphism $\g\to\gl(W)$ factors through a group of block upper triangular matrices which corresponds to an abelian Lie algebra.

So $\g$ has an abelian quotient if representation is nontrivial. 

So $\g$ has an abelian, hence solvable, ideal if the representation is non-trivial.  

\paragraph{Case 2:} 

Let $W$ be a representation of $\g$, $U \subseteq W$ a subrep. We want a section of $W\onto W/U$. 
\begin{enumerate}[label=(\roman*)]

\item Assum $W/U = \C$

\item Consider the action $\langle C_V \rangle_{V\text{ nontrivial irrep }}\curvearrowright W$

Then $W = \bigoplus W_\lambda$, $\lambda:\langle C_V\rangle \to \C$, where $W_\lambda$ are the generalized eigenspaces of $\langle C_V \rangle$. 

Then $p = \oplus p_\lambda:W_\lambda\to\C$. $p_\lambda = 0$ for $\lambda\neq 0$, and $p_0$ is surjective. 

It is enough to find a splitting $s$ of $p_0:W_0\onto\C$. 

But $W_0$ is trivial by case 1, so any $s$ works. 

\item Suppose $W/U$ is arbitrary. We have a SES
\[
\exactshort{U}{\iota}{W}{\pi}{W/U}
\]

Hitting this SES with the functor $\Hom_\C(W/U,-)$, we get 

\[
\exactshort{\Hom_\C(W/U),U)}{\iota^*}{\Hom_\C(W/U,W)}{\pi^*}{\Hom_\C(W/U,W/U)}
\]
It is enough to split this sequence. We can use the $s'$ 

\end{enumerate}


\paragraph{Case 3:} Do induction. 

Proof in Kirilov: 

The SES's $U\into W \onto W/U$ is controlled by $H^1(\g,\underline{\Hom}_\C(W/U,U)) = 0$. But this group is $Ext^1_{Ug}(W/U,U)$. 

So $Ext^1$ vanishes, and thus every every such extension splits. 

$H^1(\g,V) = 0$ for a vector space $V$, and $Ext^1(A,B)$ is $H^1(\g,\Hom(A,B))$. 

\

\cor

Let $\g$ be reductive (i.e. $\rad \g = \mk{z}(\g)$). Then 
\[
\g = \mk{z}(\g)\oplus\g/\mk{z}(\g)
\]

\proof

Consider 
\[
\exactshort{\g}{}{\g/\mk{z}(\g)}{\ad}{\gl(\g)}
\]

Given by the adjoint rep. $\g$ is semisimple, and by the theorem $\g = \mk{z}(\g) \oplus \g/\mk{z}(\g)$. 

So $\g \subset \mk{z}(\g) \oplus \g/\mk{z}(\g)$ as Lie algebras. 

\qed

\underline{Goal for the rest of the course:}

Understand the analogue of 
\[
\langle\text{diagonal matrices}\rangle\into \sl_n
\]

For arbitrary semisimple Lie algebras. 

\exm

Consider $h\in \sl_2$. Suppose $h\curvearrowright $representations of $\sl_2$. 

Then $h$ is always diagonalizable and irreps were classified in terms of largest eigenvalues of $h$. 

\defn

Let $\g$ be a semisimple Lie algebra. $x \in \g$ \underline{semisimple} if $\ad(x) \in \gl(\g)$ is diagonalizable. 

$x \in \g$ is \underline{nilpotent} if $\ad(x) \in \gl(\g)$ is nilpotent. 

\exm

In $\sl_2 = \langle h, e, f \rangle$, $h$ is semisimple and $e, f$ are nilpotent. 

\thm

Let $\g$ be semisimple over $\C$, $x \in \g$. Then there is a unique way to write $x = x_s + x_n$, $x_s$ semisimple and $x_n$ nilpotent, with $[x_s,x_n] = 0$, and $\ad(x_s) = P(\ad(x)), P \in t\c[t]$. 

\cor

If $\g$ is semisimple then there are semisimple elements. 

\proof

\qed

\section*{Lecture 19, 20/3/25}

Last time, we proved that if $\g$ is a semisimple Lie algebra over $\C$, then all finite dimensional representations of $\g$ are themselves semisimple, i.e. direct sums of irreducibles. 

\exm

Consider $\sl_n = \{x\in\gl_n \mid \tr x = 0 \}$

We will denote by $\mk{t}_n \subseteq \sl_n$ the diagonal matrices. 

Let $E_{ij}$ be the matrix with 1 in the $i, j$th entry and 0 elsewhere. If $i\neq j$ then $E_{ij} \in \sl_n$. 

$\mk{t}_n$ is commutative with a basis given by $E_{i,i} - E_{i+1,i+1}$.

\prop

For every $x \in \mk{t}_n$ and representation $\rho:\sl_n\to\gl_n$, $\rho(x)$ is diagonalizable.

\proof

It is enough to show that $\rho(E_{i,i} - E_{i+1,i+1})$ is diagonalizable. 

But this is a copy of $h$ in a subalgebra isomorphic to $\sl_2$, and this is diagonalizable because of facts we know about the rep theory of $\sl_2$. 

We have a distinguished class of elements $\{E_{i,i}- E_{j,j} \mid i \neq j \}\subseteq \mk{t}_n$

Such that 
\[
\langle E_{i,j}, E_{i,j} - E_{j,i}, E_{ji}\rangle \simeq \sl_2
\]

We can break $\sl_n$ into eigenspaces for the $\mk{t}_n$-action (which is by $\ad$). 

Then $\sl_n = \mk{t}_n \oplus \bigoplus_{i\neq j}\Span(E_{ij})$, because the centralizer of $\mk{t}_n$ is $\mk{t}_n$. 

The direct sum is indexed by some functionals on $\mk{t}_n$ (namely the eigenvalues). But the killing form $K(x,y) = \tr(\ad(x)\ad(y)|\sl_n)$ is a nondegenerate pairing on $\mk{t}_n$, so furnishes a canonical isomorphism between $\mk{t}_n$ and its dual. 

So each $\lambda$ corresponds to $K(x_\lambda,-)$ for some $x_\lambda \in \mk{t}_n$, and these turn out to be the $E_{i,j}$'s. (?)

\qed

\paragraph{Remark:} There's a more general story for Cartan subalgebras of $\sl_n$. 

Now we have to come up with a way to say ``diagonal matrix" for an abstract Lie algebra. 

\defn

Let $\g$ be a semisimple Lie algebra. We say $x \in \g$ is \underline{semisimple} if $\ad(x)$ is diagonalizable, and we say $x \in \g$ is \underline{nilpotent} if $\ad(x)$ is nilpotent. 

\defn

$\Der(\g) \subseteq \gl(\g)$ is $\{x\in\gl(\g) \mid [ax, b] + [a, xb] = x[a,b]\}$.

This is the space of derivations on $\g$. One can check as an exercise that it is in fact a subalgebra of $\gl(\g)$. 

\thm

Let $\g$ be semisimple, $x \in \g$. Then $x$ can be written uniquely as $x = x_s + x_n$ with $x_s$ semisimple, $x_n$ nilpotent, and $\ad(x_s) = P(\ad(x)) \in t\C[t]$. 

\proof

What we need is a characterization of the image of $\ad:\g\to\gl(\g)$.

\prop

If $\g$ is semisimple, then $\ad:\g\to\Der(\g)$ is an isomorphism. 

\proof

First, $\ker\ad = \mk{z}(\g)$, which is zero because $\g$ is semisimple, thus this is injective. 

Extend the killing form $K$ from $\g$ to $\Der(\g)$ (which we can do because this map is injective) by saying $K(\delta_1,\delta_2) = \tr(\delta_1\delta_2\mid \g)$. 

Observe $K|_\g$ is the Killing form of $\g$, which is non-degenerate by Cartan's criterion. 

Hence $\Der(\g) = \g \oplus \g^\perp$, because $\g \cap \g^\perp = 0$ and $\dim \g + \dim \g^\perp \geq \dim \Der(\g)$. 

\claim

$\g$ is an ideal. 

\proof

\begin{align*}
[\delta,\ad(x)] & = \ad\delta(x) \\
\end{align*}

\qed

So $\g$ is an ideal, so $\Der(\g) = \g \oplus \g^\perp$, not just as vector spaces, but as Lie algebras. 

So then $\g^\perp$ and $\g$ commute, i.e. for all $\delta \in \g^\perp$, $x \in \g$, $\delta(x) = 0$. So then $\g^\perp = 0$.

This proves the claim. 

\qed

Now we can prove the theorem. 

\proof

Uniqueness is easy, and follows from the uniqueness of the usual Jordan decomposition on $\gl(\g)$. 

For existence, write $\ad(x) = \ad(x)_s + \ad(x)_n$. 

It is enough to show $\ad(x)_s = \ad(x_s)$ for some $x_s \in \g$, because then we can set $x_n = x - x_s$, and we get the usual Jordan decomposition. 

By the proposition, to show this, it is enough to show that $\ad(x)_s$ is a derivation. 

$\g = \bigoplus \g_\lambda$, where $\g_\lambda$ are the generalized eigenspaces of $\ad(x)$. 

$\ad(x)$ acts on $\g_\lambda$ by $\lambda\cdot \Id$. 

\claim
\[
[\g_\lambda,\g_\mu]\subseteq\g_{\lambda+\mu}
\]

\proof

Compute

\qed

\cor

If $\g \neq 0$ is a semisimple Lie algebra, then there exists a semisimple element in $\g$. 

\proof

If this is not the case, then $x = x_n$ for all $x \in \g$, i.e. the image of $\ad$ consists of nilpotent matrices, which implies $\g$ is nilpotent by a problem on homework 1.

\prop

Let $\g$ be semisimple, $x \in \g$ semisimple, $\rho:\g\to\gl_n$ a representation. Then $\rho(x)$ is diagonalizable.  

\proof

WLOG, $\rho$ is irreducible. 

Let $\C^N \supseteq \bigoplus_\lambda V_\lambda$, where $V_\lambda$ is the honest (meaning NOT generalized) eigenspace of $\rho(x)$. 

It is enough to show $\bigoplus_\lambda V_\lambda$ is a subrepresentation, because $\rho$ is irreducible. 

Because $\rho$ is semisimple, $\g = \bigoplus \g_\alpha$, where $\g_\alpha$ is the $\alpha$-eigenspace of $\ad(x)$. 

To show $V_\lambda$ is a subrepresentation it's enough to show that acting by an element of $\g$ stays in the sum, so it's enough to do it for a basis, so it's enough to do it for an eigenvector. 

Fix $y \in \g_\alpha, v \in V_\lambda$. Then 
\[
xyv = yxv + [x,y]v = \lambda yv + \ad(x)(y)\cdot v = \lambda yv + \alpha yv = (\lambda + \alpha)yv
\]
So $yv \in V_{\alpha + \lambda}$. 

\qed

This completes the proof of the theorem. 

\qed

\defn

Let $\g$ be a semisimple Lie algebra over $\C$. Then
\begin{itemize}

\item $\mk{t}\subseteq\g$ is \underline{toroidal} if it is commutative and consists entirely of semisimple elements 

\item $\h\subseteq\g$ is \underline{Cartan} if it is toroidal, and $\{x\in\g\mid [x,y] = 0 \forall y \in \h\}$. That is, $\h$ is its own centralizer. 

\end{itemize}

\thm

Let $\g$ be semisimple, $\mk{t}\subseteq\g$ toroidal. 
\begin{enumerate}

\item $\g = \bigoplus \g_\alpha$, $\alpha \in \mk{t}^*$, $\g_\alpha = \{x \in \g \mid [y,x] = \ad(y)x \forall y \in \mk{t}\}$. 

That is, the adjoint action is diagonalizable. 

\item $[\g_\alpha, \g_\beta]\subseteq\g_{\alpha+\beta}$. 

\item If $\alpha+\beta \neq 0$, then $\g_\alpha,\g_\beta$ are orthogonal with respect to $K$. 

\item The Killing form induces a non-degenerate pairing $\g_\alpha \times \g_{-\alpha}\to\C$. In paticular, $K|_{\g_0}$ is non-degenerate.

\end{enumerate}

\proof
\,
\begin{enumerate}

\item Simultaneously diagonalizable 

\item Special case of computation from before

\item Take $x \in \g_\alpha, y \in \g_\beta$. Goal: compute $\tr(\ad(x)\ad(y)|\g)$. 

$\ad(x)\ad(y)|(\g_\lambda) \subseteq \g_{\lambda+\alpha+\beta}$ which has zero intersection $\g_\lambda$. 

So the matrix of $\ad(x)\ad(y)$ is zero on the diagonal, so $\tr(\ad(x)\ad(y)|\g) = 0$. 

\item The Killing form is non-degenerate. 

\end{enumerate}

\thm

Let $\g$ be a semisimple Lie algebra over $\C$, and suppose $\mk{t}\subseteq\g$ is a maximal toroidal subalgebra. Then $\mk{t}$ is a Cartan subalgebra. 

\cor

Cartan subalgebras exist

\proof

First we must show there exists a non-zero toroidal sub-algebra of $\g$. Then take a maximal via Zorn's lemma or the like. 

\qed

\proof

Now let's prove the theorem. 

Let $\mk{t}$ be a maximal toroidal subalgebra. 
\[
\g = \bigoplus_{\alpha\in\mk{t}^*}\g_\alpha
\]
\[
\g_\alpha = \{x\in \g \mid [y,x] = \alpha(y)x\forall y \in \mk{t}\}
\]
Now note $\g_0 = C(\mk{t})$, the centralizer of $\mk{t}$. 

We want to show $\mk{t} = \g_0$. 

Note from what we've just shown that $K|_{\g_0}$ is non-degenerate. 

\claim 

Let $x in C(\mk{t}) = \g_0$. Then $x_s, x_n \in C(\mk{t})$. 

\proof

We have $\ad x_s = P(\ad x)$, so for all $y \in \mk{t}$, $(\ad x_s)(y) = P(\ad x)(y) = 0$, because $P \in t\C[t]$. 

But this implies $x_s \in C(\mk{t})$, which implies that $x_n = x - x_s \in C(\mk{t})$

\qed

Now note that $C(\mk{t})$ is reductive because $K|_{C(\mk{t})}$ is non-degenerate. 

\claim

$C(\mk{t})$ is commutative

\proof

First note $C(\mk{t}) = \mk{z}(C(\mk{t}))\oplus\g'$, with $\g'$ semisimple. $\mk{t}\subseteq\mk{z}(C(\mk{t}))$

Let $x_s \in \g'$ be semisimple. 

Then $\langle \mk{t}, x_s \rangle$ contradicts maximality of $\mk{t}$. 

\qed

\claim

$C(\mk{t})$ contains no nilpotents. 

\proof

Fix some $x \in C(\mk{t})$ nilpotent, and fix $y \in C(\mk{t})$ arbitrary. Then
\begin{align*}
K(x,y) & = \tr(\ad(x)\ad(y)|\g) \\
& = \tr(\ad(y)\ad(x)|\g)
\end{align*}

By previous point, $\ad(x),\ad(y)$ commute, and so their product is nilpotent, and hence the trace is zero. 

So then $x$ has to be zero by nondegeneracy of the Killing form on $C(\mk{t})$

\qed

Finally, $C(\mk{t})$ is toroidal because it is commutative and for all $x \in C(\mk{t})$, $x_s,x_n \in C(\mk{t})$, so $x_n = 0$ by the previous point. So $x = x_s$, i.e. $x$ is semisimple. 

Hence $\t = C(\mk{t})$, because $\mk{t}$ is maximal toroidal. 

\qed

\paragraph{Fact:} $\Aut(\g)$ acts transitively on the Cartan subalgebras. 

\subsection*{\underline{Root system}}

Let $\g$ be semisimple, $\h\subseteq\g$ a Cartan subalgebra (i.e. a commutative subalgebra consisting of semisimple elements which is its own centralizer). 

\thm
\,
\begin{enumerate}

\item $\g \simeq \h \oplus \bigoplus_{\alpha\in R}\g_\alpha$, where $R$ is the set $\{\alpha \in \mk{h}^*\setminus\{0\}\mid \g_\alpha\neq0\}$, and $\g_\alpha = \{x\in \g \mid [y, x] = \alpha(y)x\forall y \in \h\}$ 

$R$ is called the set of \underline{roots}

\item $[\g_\alpha,\g_\beta] \subseteq \g_{\alpha+\beta}$

\item If $\alpha+\beta\neq 0$, then $\g_\alpha,\g_\beta$ are orthogonal wrt the Killing form

\item $K:\g_\alpha\times\g_{-\alpha}\to\C$ is non-degenerate. In particular, $K|_{\h}$ is non-degenerate.

\end{enumerate}

\proof

$\h = \g_0$. 

\qed

\paragraph{Observation:} $K|_{\h}$ is non-degenerate, thus furnishes an isomorphism $\h\simeq\h^*$ sending $y$ to $K(y,-)$.

So given $\alpha \in R$, there exists a unique $H_\alpha \in \h$ such that $\alpha = K(H_\alpha,-)$. 

\exm

Consider $\sl_3$. Then $\h$ is the diagonal matrices with trace 0.

Then $\h^* = \langle e_1, e_2, e_3\rangle/(\sum e_i = 0)$ with $e_i(M) = (M)_{ii}$. 

Then $R = \{\pm(e_1 - e_2) \pm (e_1 - e_3) \pm (e_2 - e_3)\}$

\section*{Lecture 20, 25/3/25}

\exm

Let $\g = \sl_n$, $\h$ the diagonal matrices. 

We have shown there is a decomposition $\sl_n = \h\oplus \bigoplus \Span(E_{ij})$, which we can use to find many copies of $\sl_2$ inside $\sl_n$. 

\thm
Let $\g$ be a Lie algebra, $\h$ a Cartan subalgebra. 
\,
\begin{enumerate}

\item $\g = \h\oplus\bigoplus_{\alpha\in R}\g_\alpha$, where $\g_\alpha = \{x\in\g \mid [h,x] = \alpha(h)x\forall h \in \h\}$, $\alpha \in \h^*$, where $R = \{\alpha\in \h^*\setminus\{0\} \mid \g_\alpha\neq0\}$, and $R$ is called the set of roots. 

\item $[\g_\alpha,\g_\beta] \subseteq \g_{\alpha+\beta}$

\item If $\alpha+\beta\neq0$, then $\g_\alpha,\g_\beta$ are orthogonal with respect to $K$. 

\item $K:\g_\alpha\times\g_{-\alpha} \to \C$ is nondegenerate; in particular, $K|_\h$ is non-degenerate. 

\end{enumerate}

\proof

\qed

\paragraph{Observation:} There is a canonical isomorphism between $\h$ and $\h^*$ given by $x \mapsto K(x,-)$. 

So given $\alpha \in R$, there is a unique $H_\alpha \in \h$ such that $K(H_\alpha,-) = \alpha$. 

\paragraph{Notation:} Given $\alpha,\beta\in\h$, we write $(\alpha,\beta) \eqdef K(\alpha,\beta)$. 

Given $\alpha \in \h^*, \beta\in\h$, we write $\langle\alpha,\beta\rangle \eqdef \alpha(\beta)$. 

\paragraph{Goal:} Construct many copies of $\sl_2$ inside of $\g$. 

The idea will be to take $e \in \g_\alpha, f \in \g_{-\alpha}$ such that $(e,f) \neq 0$, and then consider the subalgebra generated by $e, f$. 

\lem

Let $e \in \g_\alpha, f \in \g_{-\alpha}$. Then $[e,f] = (e,f)H_\alpha$. 

\proof
\,
\begin{itemize}

\item First, observe $[e,f] \in \h$. 

\item Let $x \in \h$. What is $([e,f],x)?$ Well, $K$ is an invariant bilinear form, so this is equal to 
\begin{align*}
(e,[f,x]) & = -(e,[x,f]) \\
& = - (e,\alpha(x)f) \\
& = \alpha(x)(e,f) \\
& = (H_\alpha,x)(e,f) \\
& = ((e,f)H_\alpha,x) \\
\end{align*}
So $H_{[e,f]}(x) = (e,f)H_\alpha(x)$

\end{itemize}

\lem
\,
\begin{enumerate}

\item Let $\alpha \in R$. Then $(H_\alpha,H_\alpha) \neq 0$. 

\item If $e \in \g_\alpha, f \in \g_{-\alpha}$ such that $(e,f) = \frac{2}{(\alpha,\alpha)}$, set $h_\alpha = \frac{2H_\alpha}{(\alpha,\alpha)}$

Then $\langle e, f, h_\alpha \rangle \simeq \sl_2$. 

Further, $\langle h_\alpha,\alpha \rangle = 2$. 

\end{enumerate}

\proof
\,
\begin{enumerate}

\item Suppose $(\alpha,\alpha)\eqdef (H_\alpha,H_\alpha) = 0$. Pick $e \in \g_\alpha, f \in \g_{-\alpha}$ with $(e,f)\neq0$ (possible as $K$ is non-degenerate). 

Consider the sub-algebra $\langle e, f, \underbrace{[e, f]}_{=x}\rangle \eqdef \mk{s}$. 

We have $[x,e] = [(e,f)H_\alpha,e] = (e,f)\alpha(H_\alpha)e = 0$. Same argument shows $[x,f] = 0$. 

So $x \in \mk{z}(\langle e, f, x\rangle)$, so $\mk{s}$ is solvable. 

Now, we have the upper triangularizable representation $\ad:\mk{s}\to\gl(\g)$, so $\ad(x) = \ad([e,f])$ is nilpotent. But $x$ is a multiple of $H_\alpha$, which is semisimple, so $x = 0$. 

So $x = (e,f)H_\alpha$ with $(e,f)$ nonzero. 

\item Directly compute $[e,f],[h,f],[h,e]$. 

\end{enumerate}

\qed

\defn

For each $\alpha \in R$, choose $e, f$ as above, and set $(\sl_2)_\alpha \subseteq \g$ to be the sub-algebra generated by $e, f, [e,f]$. 

It will turn out later that this is independent of the choice of $e, f$. 

\lem

Fix $(\sl_2)_\alpha \subseteq \g$ as before. Then $V \eqdef \C h_\alpha \oplus \bigoplus_{k\in \Z_{\neq0}}\g_{k\alpha}$ is irreducible as a $(\sl_2)_\alpha$-representation. 

\proof

First, this decomposition is preserved by $\sl_2:$, because $\ad(e):\g_{k\alpha} \to \g_{(k+1)\alpha}$, and $\ad(f):\g_{k\alpha}\to\g_{(k-1)\alpha}$, and those follow from the fact that $[\g_\alpha,\g_\beta]\subseteq\g_{\alpha+\beta}$. 

To see that it is irreducible, we compute the eigenvalues of $h_\alpha \curvearrowright V$. Indeed, $\ad(h_\alpha)|_{\g_\alpha} = 2\cdot\Id$, and $\ad(h_\alpha)|_{\g_{k\alpha}} = 2k$. 

This implies $V$ is a direct sum of $\Sym^n V_{std}$ for $n$ even, and 0 appears as an eigenvalue with multiplicity 1, so this is irreducible. 

\qed

\cor

$\dim \g_\alpha = 1$ for all $\alpha$. 

\proof

\qed

\paragraph{Fact:} $V \simeq (\sl_2)_\alpha$. 

\section*{Lecture 21, 27/3/25}

\defn[Root system]
Let $E$ be a real vector space with pairing $(-,-)$, $R \subseteq E\setminus\{0\}$ such that 
\begin{enumerate}

\item[R1] $R$ spans $E$ 

\item[R2] The quantity $\eta_{\alpha\beta} \eqdef \frac{2(\alpha,\beta)}{(\beta,\beta)} \in \Z$ for all $\alpha,\beta\in R$

\item[R3] The function $s_\alpha:E\to E$, sending $\lambda \mapsto \lambda - \frac{2(\alpha,\lambda)}{(\alpha,\alpha)}\alpha$ preserves $R$ for all $\alpha \in R$.

\item[R4 - Reduced] If $\alpha, c\alpha \in R$, then $c = \pm 1$. 

\end{enumerate}

We can rephrase $R3$ by saying $s_\alpha$ is the reflection actross $\{\lambda \mid (\lambda,\alpha) =0\}$. 

We can rephrase $R2$ by saying the projection of $\beta$ onto $R_\alpha$ has half-integer length. 

\paragraph{Last time:} 

Let $\g$ be a semisimple Lie algebra over $\C$, $\h\subseteq\g$ a Cartan subalgebra. Then $\g = \h \oplus \bigoplus_{\alpha\in R}\g_\alpha$. 

We showed this by constructing copies of $\sl_2$ for each $\alpha$, $(\sl_2)_\alpha \subseteq \g$, given by $\langle e \in \g_\alpha, t \in \g_{-\alpha}, h_\alpha \in \h\}$. 

Then $\C h_\alpha\oplus\bigoplus_{k\in\Z_{\neq0}}\g_{k\alpha}$ is irreducible as a $(\sl_2)_\alpha$-represntation, where $h+\alpha \curvearrowright \g_{k\alpha}$ by $\cdot 2k\Id$. 


\cor
\,
\begin{itemize}

\item $\g_\alpha$ is 1-dimensional 

\item $(\sl_2)_\alpha$ is independent of choices. 

\item If $\alpha,\beta$ are roots with $\beta = k\alpha$, then $k = \pm 1$. 

\end{itemize}

\proof

We will prove the third corollary (we did the other two last time). 

We have $(\sl_2)_\alpha\subseteq V_\alpha$, so $(\sl_2)_\alpha = V_\alpha$ by irreducibility. 

\qed

\thm

Let $\g,\h$ be as before, $\g = \h \oplus \bigoplus_{\alpha\in R}\g_\alpha$. 

\begin{enumerate}

\item $R$ spans $\h^*$ as a $\C$-vector space. 

\item For all $\alpha, \dim \g_\alpha = 1$

\item Setting $h_\alpha = \frac{2H_\alpha}{(\alpha,\alpha)}$, with $(H_\alpha,-) = \alpha(-)$, we have
\[
\beta(h_\alpha) = \frac{2(\alpha,\beta)}{(\alpha,\alpha)} \in \Z
\]
with $\alpha,\beta \in R$. 

\item $s_\alpha: \h^*\to\h^*$ given by 
\[
s_\alpha(\lambda) = \lambda - \lambda(h_\alpha)\alpha = \lambda - \frac{2(\alpha,\lambda)}{(\alpha,\alpha)}
\]
sends roots to roots. 

\item If $\alpha$ is a root, $c\alpha$ a root, then $c = \pm 1$

\item Let $\alpha,\beta \neq \pm \alpha$. Then $V_{\alpha,\beta} = \bigoplus \g_{\beta+k\alpha}$ is irreducible as $(\sl_2)_\alpha$-representations

\item Let $\alpha,\beta, \alpha+\beta$ be roots. Then $[\g_\alpha,\g_\beta] = \g_{\alpha+\beta}$. 

\end{enumerate}

\proof
\,
\begin{enumerate}

\item Suppose there exists some $x \in \h$ such that $\alpha(x) = 0$ for all roots $\alpha$. So $x \in \mk{z}(\g)$, so $x = 0$. 

\item Follows from irreducibility of $V_\alpha$

\item $\beta(h_\alpha) = $eigenvalue of $h_\alpha\curvearrowright \g_\beta$. But $h_\alpha \in (\sl_2)_\alpha$, and acts on $V_{\beta+k\alpha}$. This is an $\sl_2$-representation, so the eigenvalues must be integers. 

\item Consider the action $(\sl_2)_\alpha\curvearrowright V_{\alpha,\beta}$. We want to show $s_\alpha(\beta)$ is a root, i.e. $g_{s_\alpha(\beta)} \neq 0$

\begin{enumerate}

\item[Case 1] $n\geq 0$. Fix $0\neq x\in\g_\alpha$. Then $f^nx \in \g_{\beta-n\alpha}$, where $f^nx$ denotes the action of $x$ n times. 

\item[Case 2] If $n \leq 0$, replace $f$ by $e$. 

\end{enumerate}

\item We have ruled out every case but $c = \pm 1, 2, \frac12$. But we can assume $c \in \Z$. We ruled out 2 but I missed it :(

\item Eigenspaces of $h_\alpha$ are 1-dimensional. 

\item Follows from 6 - if $[\g_\alpha,\g_\beta] = 0$, then $\g_\beta$-generates a sub-$(\sl_2)_\alpha$-representation, which contradicts irreducibility. 

\end{enumerate}

\qed

\section*{Lecture 22, 4/1/25}

\paragraph{Goal:} Explain the correspondence between semisimple Lie algebras and root systems. We've proven that given a semisimple Lie algebra $\g$ with Cartan subalgebra $\h$, $R \in \h^*$ roots, and killing form $K$. Then if $E = \Span(\R)$, then $K|_E$ is a root system. 

We finish the proof of the theorem. 

\proof

We want to show that $K|_E$ is positive definite. 

Let $h_\alpha$ span $\h^*$ (we know this to be true). 

\claim

For $\beta \in R$, $\beta(h_\alpha) \in \Z$

\proof

Follows from being an $\sl_2$-rep

\qed

So if $\sum c_\alpha h_\alpha \in E$, i.e $c_\alpha \in \R$, $\beta(\sum c_\alpha h_\alpha)\in\R$. 

So 
\begin{align*}
K(\sum c_\alpha h_\alpha, \sum c_\alpha h_\alpha) & = \tr(\ad(\sum c_\alpha h_\alpha)^2 ]\
& = \sum_\beta \beta(\sum c_\alpha h_\alpha)^2 \\
& \geq 0
\end{align*}
This is strictly positive, because if this is zero, then $\sum c_alpha h_\alpha \in \mk{z}(\g) = 0$. 

\qed

Now we want to see how to get a Lie algebra from a root system.

\paragraph{Idea:} Imitate upper triangular matrices. 

\paragraph{Choose:} $t \in E$ such that $(t,\alpha)\neq0$ for all roots $\alpha$.

Then $R = R^+ \cup R^-$, where
\begin{align*}
R^+ & \eqdef \{\alpha\in R \mid (t,\alpha)>0\} \\
R^- & \eqdef \{\alpha\in R \mid (t,\alpha)<0\}
\end{align*}
We call $R^+$ the \underline{positive roots} and $R^-$ the \underline{negative roots}

\paragraph{Observe:} If a root system is associated to some $(\g,\h)$, then 
\[
\g = \h\oplus \underbrace{\bigoplus_{\alpha\in R^+}\g_\alpha}_{\eta_+} \oplus \underbrace{\bigoplus_{\alpha\in R^-}\g_\alpha}_{\eta^-}
\]

\exm

$\eta_+,\eta_-$ are nilpotent sub-algebras.

\proof

A picture

\qed

\defn

$\Phi \subseteq R^+$ is $\alpha \in R^+$ such that $\alpha \neq \beta + \gamma$ for any $\gamma,\beta \in R^+$. 

This is the set of \underline{simple roots}. 

\prop

Any positive root is a positive integer linear combination of simple roots. 

\proof

Follows from $\Phi$ being a basis (exercise (easy)). And any $\alpha \in R$ is a unique $\Z$-linear combination of simple roots. 

\qed

\paragraph{Fact:} If $\alpha,\beta\in R$< $|\alpha|>|\beta|$, $\alpha \neq t\beta$. Then there's a finite set of possible angles between $\alpha,\beta, $and $\frac{|\alpha|}{|\beta|}$. That set is
\[
\{\frac{\pi}{2},\frac{2\pi}{3},\frac{\pi}{3},\frac{3\pi}{4},\frac{\pi}{4},\frac{5\pi}{6},\frac{\pi}{6}\}
\]

\paragraph{Fact:} If $\alpha,\beta$ are simple roots, $(\alpha,\beta)\leq0$. 

\cor

$\g$ is determined, up to isomorphism, by its root system. 

\proof

Let $\h = E\otimes\C$, and let $\g = \h \oplus \bigoplus_{\alpha\in R}\g_\alpha$, where $\g_\alpha$ are 1-dimensional. 

Relations: $\h\curvearrowright \g_\alpha$ via $\alpha_i$, $\h$ commutative. 

For each $\alpha \in \Phi$, choose $e_\alpha \in \g_\alpha$. 

Then $[e_\alpha,e_{\alpha'}] \in \g_{\alpha+\alpha'}$. 

For each $\beta \in R^+$, there is a unique element of $\g_\beta$ obtained as nested commutator of $e_\alpha$'s. 

So there is a unique $f_\beta$, $\beta \in R$, such that $[e_{-\beta},f_\beta] = h_\beta \in \h$, where $h_\beta = \frac{2H_\beta}{(\beta,\beta)}$, $(H_\beta,-) = \beta$. 

For a complete set of relations: Kirillov Chapter 8. 

\qed

\paragraph{Observation}

Given root systems $R_1, R_2$, $R_1\oplus R_2$ is a root systems. 

\defn

$R$ is \underline{irreducible} if it is not a direct sum of root systems. 

\lem

If $\g$ is simple, its root system is irreducible. 

\proof

\qed

\defn

If $R$ is a root system with a set of simple roots $\Phi$, we call the 2-tuple $(R,\Phi)$ a \underline{polarized root system}. 

Cartan matrix: 
\[
(\frac{2(\alpha_i,\alpha_j)}{(\alpha_i,\alpha_i)})_{\alpha_i,\alpha_j\in \Phi}
\]
The diagonal entries are 2, the off-diagonal are all nonpositive integers. 

\defn

A \underline{Dynkin diagram} is a graph with vertex set $\Phi$, and for $\alpha,\beta\in\Phi$, we connect by 1 edge of the angle between them if the angle is $\frac{2\pi}{3}$, 2 edges if $\frac{3\pi}{4}$, 3 edges if $\frac{5\pi}{6}$, and 0 edges if $\frac{\pi}{2}$. 

If the root system is irreducible, the graph is connected-otherwise we could find an irreducible subsystem. 

We make it a digraph by having an arrow from the longer to the shorter root. 

\paragraph{Classification:}

I'm not fucking drawing these root systems again...

\section*{Lecture 23, 4/3/25}

Let $\g$ be a semisimple Lie algebra, $\h \subseteq \g$ a Cartan subalgebra. 

We have a set of roots $R \subseteq \h^*$. We can write 
\[
\g = \h \oplus \bigoplus_{\alpha\in R}\g_\alpha
\]

We define $(\sl_2)_\alpha$ as the sub algebra generated by $\g_\alpha,\g_{-\alpha}$, with its canonical element $h_\alpha = \frac{2H_\alpha}{(\alpha,\alpha)}$, where $(H_\alpha,-) = \alpha(-)$. 

We let $E = \Span_\R(R)\subseteq\h^*$. This is a root system. Choosing a $t \in E$ (last choice) such that $(t,\alpha)\neq0$ for all $\alpha \in R$. We call $R^+$ the roots that pair positively with $t$ (i.e. $(\alpha,t) > 0$), and $R^-$ the roots that pair negatively. 

We call $n_+ = \bigoplus_{\alpha \in R^+}\g_\alpha$, and $n_- = \bigoplus_{\alpha\in R^-}\g_{-\alpha}$. Then the above equation can be written 
\[
\g = \h\oplus n_+\oplus n_-
\]

Suppose $V$ is an irrep of $\g$. For $\lambda\in\h^*$, we define $V[\lambda] = \{v\in V \mid xv = \lambda(x)v\,\forall x \in \h\}$. 

\prop

$V = \bigoplus_{\lambda\in\h^*}V[\lambda]$

\proof

\prop

If $V$ is any finite dimensional irrep of $\g$, and $V[\lambda] \neq 0$, then $\lambda(h_\alpha) \in \Z$. 

\proof

$V|_{(\sl_2)_\alpha}$ is an $\sl_2$-representation.

\qed

\qed

\defn
\,
\begin{enumerate}

\item The \underline{Root lattice $Q$} is the $\Z$-span of $R$

\item $Q^*$ is the $\Z$-span of the $h_\alpha$, the coroot lattice.

\item $P = \{\lambda \in \h^* \mid \lambda(h_\alpha)\in\Z\}$. The weight lattice.

\end{enumerate}

Note $Q$ and $Q^*$ are not dual lattices despite the notation; $Q$ is dual to $P$. 

\defn

The \underline{character} of $V$ is $f:P\to\Z$, $\lambda\mapsto \dim V[\lambda]$.

This will turn out to classify irreps, but we won't prove that here. 

\defn

$v \in V[\lambda]$ is a \underline{highest weight vector} if it is nonzero and $e_\alpha\cdot v = 0$ for all $\alpha \in R_+$. 

\paragraph{Computation:} $\g_\alpha\otimes V[\lambda] \to V[\lambda+\alpha]$. 

\defn

A \underline{highest weight representation} is one generated by a highest weight vector. 

\prop

Any finite dimensional irrep of $\g$ is a highest weidhgt representation

\proof

Choose $\lambda$ with $V[\lambda]\neq0$ such that $(\lambda,t)$ is maximal. 

Then $v \in V[\lambda]$ generates $V$ by irreducibility. 

\qed

\prop

Suppose $V[\lambda]\neq0$. Then for all roots $\alpha$, $V[s_\alpha(\lambda)]\neq0$. 

\proof

$(\sl_2)_\alpha\curvearrowright \oplus_kV[\lambda+k\alpha]$. This implies $\dim V[\lambda+k\alpha] = \dim V[s_\alpha(\lambda)]$. 

\qed

\defn

Let $\lambda \in \h^*$. Define $I_\lambda \subseteq U\g$ to be the left ideal generated by $n_+$ and $(x-\lambda(x))_{x\in\h}$. Then define
\[
M_\lambda \eqdef U_\g / I_\lambda
\]
We define $v_\lambda \in M_\lambda$ to be the image of 1 in $U\g$.

Observe: $v_\lambda$ generates $M_\lambda$, $n_+\cdot v_\lambda = 0$, and $x\cdot v_\lambda = \lambda(x)v_\lambda$ for all $x \in \h$. 

This is called a \underline{Verma module}, and it is infinite dimensional. 

This is the same as $U\g\bigotimes_{U\mk{b}}\C\lambda$, where $\mk{b} = \h\oplus n_+$, and $\mk{b}$ acts on $\C\lambda$ via $n_+ \equiv 0$ and $x \in \h$ acts by $\lambda(x)$. 

\prop

If $V$ has highest weight $\lambda$, then $V = M_\lambda / W$ for some $W\subseteq M_\lambda$.

\proof

Pick $w \in V$ a highest weight generator, and consider the map $M_\lambda\to V$ given by $v_\lambda\mapsto w$. This is surjective because $w$ generates. 

\qed

Basic properties of $M_\lambda:$

There is an isomorphism $U_{n_-}\to M_\lambda$ sending $x$ to $xv_\lambda$. 

\cor

$M_\lambda[\lambda']$ is finite dimensional for all $\lambda'$, and $\dim M_\lambda[\lambda]=1$. 

\proof

\qed

So classifying the finite dimensional irreps of $\g$ is the same as classifying maximal proper submodules of $M_\lambda$. 

\thm

Suppose $\lambda \in \h^*$. Then there exists at most one finite dimensional irrep of $\g$ of highest weight $\lambda$. 

\proof

It is enough to show $M_\lambda$ has a unique maximal proper submodule. 

Let 
\[
W = \sum_{J\subseteq M_\lambda, J[\lambda] = 0}J
\]

It is maximal because if $J$ is a proper submodule, then $J[\lambda]=0$ (otherwise it would contain $v_\lambda$), and so $J[\lambda]=0$ implies $J\subseteq W$. 

It is proper for the same reason; $W[\lambda]=0$.

\qed

\defn

Let $L_\lambda = M_\lambda / W_{max}$, where $W_{max}$ is the unique maximal submodule. 

\defn

$\lambda \in P \subseteq \h^*$ is \underline{dominant integral} if $\lambda(h_\alpha) \in \Z_{\geq0}$ for all $\alpha \in R^+$, i.e. $(\lambda,\alpha) \in \Z_{\geq0}$ for all $\alpha \in R^+$. 

\thm

$L_\lambda$ is finite dimensional if and only if $\lambda$ is dominant integral. 

So this is the classification of semisimple Lie algebras. 

\cor

There is a natural bijection between finite dimensional irreps of $\g$ and dominant integral weights, given by sending $V$ to the highest weight of $V$. 

\proof

Suppose $L_\lambda$ is finite dimensional. We want to show that $\lambda$ is dominant integral. 

Given $\alpha\in R^+$, $L_{\lambda}|_{(\sl_2)_\alpha}$, $\lambda(\alpha)$ is a highest weight of this $\sl_2$-rep in $\Z_{\geq0}$(?)

Now suppose $\lambda$ is dominant integral. 

We want to show $L_\lambda$ is finite dimensional, where $L_\lambda = M_\lambda / $unique maximal proper submodule.

Fix $v_\lambda \in M_\lambda[\lambda]$ a highest weight vector (we argued earlier such a thing is unique up to scaling). 

Let $n_i = (\lambda,\alpha_i)$, $\alpha_i\in R^+$. 
\[
(\sl_2)_{\alpha_i} = \langle e_i, f_i, h_i \rangle
\]

Let $v_{\lambda_i} = f_i^{n_i+1}v_\lambda$. 

\claim

$v_{\lambda_i}$ is annihilated by all $e_j$ (this is what it means to be highest weight)

\proof

It is enough to check this for $e_j$ coming from simple roots. If $i\neq j$ then $e_i,e_j$ commute: $e_jf_i^{n+1}e_jv_\lambda-0$. 

If $i = j$ this is a statement coming from $\sl_2$-reps (?). 

Set $M_i = U\g\cdot v_{\lambda_i}\subseteq M_\lambda$. 

So then each $M_i$ is a proper submodule of $M_\lambda$, as $M_i[\lambda]=0$. 

It is enough to show that $M_\lambda/(\sum M_i)$ is finite dimensional. 

\paragraph{Observe:} In this quotient, the action of $(\sl_2)_\alpha$ on each quotient for each $\alpha$ is a finite dimensional vector space. 

$(\sl_2)_\alpha v_\lambda \subseteq M_\lambda/(\sum M_i)$ is finite dimensional. 

\defn

$V$ is \underline{integrable} if for all $v \in V$, $U(\sl_2)_{\alpha_i}\cdot v$ is finite dimensional.

\lem

Given \underline{any} representation $V$ of $\g$, the integrable elements, $V^{int}$, is an integral subrepresentation. 

\lem

Any highest weight integrable subrepresentation is finite dimensional. 

\proof

Given the lemmas, $L_\lambda$ is a quotient of $M_\lambda / (\sum M_i)$, hence $(L_\lambda)^{int}$ is nonzero. $L_\lambda$ we've shown is irreducible, but by irreducibility, $L_\lambda = (L_\lambda)^{int}$, hence by lemma 2, $\dim L_\lambda<\oo$. 

\qed

Let's prove the first lemma now.

\proof

Let $x \in \g, v \in V^{int}$. We want to show that $xv \in V^{int}$. hen $xU(\sl_2)_\alpha v \subseteq \g U(\sl_2)_\alpha v$. But this is finite dimensional. 

But $\g U(\sl_2)_\alpha v$ is stable under the action of $U(\sl_2)_\alpha$

\qed

Let's prove the second. 

\proof

Let $V$ be an integrable highest weight representation of highest weight $w$. Consider $\lambda$ such that $V[\lambda]\neq0$. 

This set is stable under reflections $s_\alpha$ for $\alpha \in R$. 

This implies the support of $w(V)$ is contained in a bounded set.

So $w(V)$ is finite. But $\dim M_\lambda[\lambda']$ is finite. So finitely many weight spaces, each of which is finite dimensional, implies $\dim V < \oo$. 

\qed




\end{document}
